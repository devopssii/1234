{"metadata":{"colab":{"provenance":[{"file_id":"1N2iIdzVYrce0jYSTIV7jaiKn60arWB36","timestamp":1710938577186},{"file_id":"12oR4bUleVRIigLl1e-d8jc2OWymIiYzc","timestamp":1710790516738}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8016837,"sourceType":"datasetVersion","datasetId":4723398},{"sourceId":8027642,"sourceType":"datasetVersion","datasetId":4731246},{"sourceId":8392318,"sourceType":"datasetVersion","datasetId":4992211}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#@markdown ## <font color=\"ffc800\"> **Check GPU type.** üëÅÔ∏è\n#@markdown ---\n#@markdown #### A higher capable GPU can lead to faster training speeds. By default, you will have a <font color=\"orange\">**Tesla T4**</font>.\n!nvidia-smi","metadata":{"cellView":"form","executionInfo":{"elapsed":484,"status":"ok","timestamp":1711482123109,"user":{"displayName":"Ab As","userId":"09234410323733171058"},"user_tz":-300},"id":"nHlyIgpo2R6Y","outputId":"983c7026-14af-4688-ed4e-f9d3b09a2cc9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade pip\n!pip install tensorflow\n!pip install gym-trading-env\n!pip install scikit-learn\n!pip install yfinance==0.2.38\n!pip install finta","metadata":{"executionInfo":{"elapsed":1238555,"status":"ok","timestamp":1711484785631,"user":{"displayName":"Ab As","userId":"09234410323733171058"},"user_tz":-300},"id":"HkvA9xSiiM1S","outputId":"e32bdd0b-06d3-4666-8c26-344203094b7b","execution":{"iopub.status.busy":"2024-08-12T09:49:54.732909Z","iopub.execute_input":"2024-08-12T09:49:54.733809Z","iopub.status.idle":"2024-08-12T09:51:06.998542Z","shell.execute_reply.started":"2024-08-12T09:49:54.733765Z","shell.execute_reply":"2024-08-12T09:51:06.997272Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.3.2)\nCollecting pip\n  Downloading pip-24.2-py3-none-any.whl.metadata (3.6 kB)\nDownloading pip-24.2-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 23.3.2\n    Uninstalling pip-23.3.2:\n      Successfully uninstalled pip-23.3.2\nSuccessfully installed pip-24.2\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.51.1)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nCollecting keras<2.16,>=2.15.0 (from tensorflow)\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.2.1\n    Uninstalling keras-3.2.1:\n      Successfully uninstalled keras-3.2.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0\nCollecting gym-trading-env\n  Downloading gym_trading_env-0.3.3-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: pandas>=1.5.3 in /opt/conda/lib/python3.10/site-packages (from gym-trading-env) (2.1.4)\nRequirement already satisfied: numpy>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from gym-trading-env) (1.26.4)\nRequirement already satisfied: gymnasium>=0.28.1 in /opt/conda/lib/python3.10/site-packages (from gym-trading-env) (0.29.0)\nRequirement already satisfied: flask>=2.2.3 in /opt/conda/lib/python3.10/site-packages (from gym-trading-env) (3.0.3)\nCollecting pyecharts>=2.0.2 (from gym-trading-env)\n  Downloading pyecharts-2.0.6-py3-none-any.whl.metadata (1.3 kB)\nCollecting ccxt==3.0.59 (from gym-trading-env)\n  Downloading ccxt-3.0.59-py2.py3-none-any.whl.metadata (111 kB)\nRequirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from gym-trading-env) (1.5.8)\nRequirement already satisfied: setuptools>=60.9.0 in /opt/conda/lib/python3.10/site-packages (from ccxt==3.0.59->gym-trading-env) (69.0.3)\nRequirement already satisfied: certifi>=2018.1.18 in /opt/conda/lib/python3.10/site-packages (from ccxt==3.0.59->gym-trading-env) (2024.2.2)\nRequirement already satisfied: requests>=2.18.4 in /opt/conda/lib/python3.10/site-packages (from ccxt==3.0.59->gym-trading-env) (2.31.0)\nRequirement already satisfied: cryptography>=2.6.1 in /opt/conda/lib/python3.10/site-packages (from ccxt==3.0.59->gym-trading-env) (41.0.7)\nRequirement already satisfied: aiohttp>=3.8 in /opt/conda/lib/python3.10/site-packages (from ccxt==3.0.59->gym-trading-env) (3.9.1)\nCollecting aiodns>=1.1.1 (from ccxt==3.0.59->gym-trading-env)\n  Downloading aiodns-3.2.0-py3-none-any.whl.metadata (4.0 kB)\nRequirement already satisfied: yarl>=1.7.2 in /opt/conda/lib/python3.10/site-packages (from ccxt==3.0.59->gym-trading-env) (1.9.3)\nRequirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from flask>=2.2.3->gym-trading-env) (3.0.2)\nRequirement already satisfied: Jinja2>=3.1.2 in /opt/conda/lib/python3.10/site-packages (from flask>=2.2.3->gym-trading-env) (3.1.2)\nRequirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from flask>=2.2.3->gym-trading-env) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from flask>=2.2.3->gym-trading-env) (8.1.7)\nRequirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from flask>=2.2.3->gym-trading-env) (1.7.0)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium>=0.28.1->gym-trading-env) (2.2.1)\nRequirement already satisfied: typing-extensions>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium>=0.28.1->gym-trading-env) (4.9.0)\nRequirement already satisfied: farama-notifications>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from gymnasium>=0.28.1->gym-trading-env) (0.0.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.3->gym-trading-env) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.3->gym-trading-env) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.3->gym-trading-env) (2023.4)\nRequirement already satisfied: prettytable in /opt/conda/lib/python3.10/site-packages (from pyecharts>=2.0.2->gym-trading-env) (3.9.0)\nRequirement already satisfied: simplejson in /opt/conda/lib/python3.10/site-packages (from pyecharts>=2.0.2->gym-trading-env) (3.19.2)\nCollecting pycares>=4.0.0 (from aiodns>=1.1.1->ccxt==3.0.59->gym-trading-env)\n  Downloading pycares-4.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8->ccxt==3.0.59->gym-trading-env) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8->ccxt==3.0.59->gym-trading-env) (6.0.4)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8->ccxt==3.0.59->gym-trading-env) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8->ccxt==3.0.59->gym-trading-env) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8->ccxt==3.0.59->gym-trading-env) (4.0.3)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=2.6.1->ccxt==3.0.59->gym-trading-env) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=3.1.2->flask>=2.2.3->gym-trading-env) (2.1.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.3->gym-trading-env) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.18.4->ccxt==3.0.59->gym-trading-env) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.18.4->ccxt==3.0.59->gym-trading-env) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.18.4->ccxt==3.0.59->gym-trading-env) (1.26.18)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prettytable->pyecharts>=2.0.2->gym-trading-env) (0.2.13)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt==3.0.59->gym-trading-env) (2.21)\nDownloading gym_trading_env-0.3.3-py3-none-any.whl (17 kB)\nDownloading ccxt-3.0.59-py2.py3-none-any.whl (3.6 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyecharts-2.0.6-py3-none-any.whl (149 kB)\nDownloading aiodns-3.2.0-py3-none-any.whl (5.7 kB)\nDownloading pycares-4.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\nInstalling collected packages: pyecharts, pycares, aiodns, ccxt, gym-trading-env\nSuccessfully installed aiodns-3.2.0 ccxt-3.0.59 gym-trading-env-0.3.3 pycares-4.4.0 pyecharts-2.0.6\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\nCollecting yfinance==0.2.38\n  Downloading yfinance-0.2.38-py2.py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: pandas>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from yfinance==0.2.38) (2.1.4)\nRequirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.10/site-packages (from yfinance==0.2.38) (1.26.4)\nRequirement already satisfied: requests>=2.31 in /opt/conda/lib/python3.10/site-packages (from yfinance==0.2.38) (2.31.0)\nCollecting multitasking>=0.0.7 (from yfinance==0.2.38)\n  Downloading multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\nRequirement already satisfied: lxml>=4.9.1 in /opt/conda/lib/python3.10/site-packages (from yfinance==0.2.38) (5.2.1)\nRequirement already satisfied: appdirs>=1.4.4 in /opt/conda/lib/python3.10/site-packages (from yfinance==0.2.38) (1.4.4)\nRequirement already satisfied: pytz>=2022.5 in /opt/conda/lib/python3.10/site-packages (from yfinance==0.2.38) (2023.3.post1)\nRequirement already satisfied: frozendict>=2.3.4 in /opt/conda/lib/python3.10/site-packages (from yfinance==0.2.38) (2.4.2)\nCollecting peewee>=3.16.2 (from yfinance==0.2.38)\n  Downloading peewee-3.17.6.tar.gz (3.0 MB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.11.1 in /opt/conda/lib/python3.10/site-packages (from yfinance==0.2.38) (4.12.2)\nRequirement already satisfied: html5lib>=1.1 in /opt/conda/lib/python3.10/site-packages (from yfinance==0.2.38) (1.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance==0.2.38) (2.5)\nRequirement already satisfied: six>=1.9 in /opt/conda/lib/python3.10/site-packages (from html5lib>=1.1->yfinance==0.2.38) (1.16.0)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from html5lib>=1.1->yfinance==0.2.38) (0.5.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance==0.2.38) (2.9.0.post0)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance==0.2.38) (2023.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance==0.2.38) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance==0.2.38) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance==0.2.38) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance==0.2.38) (2024.2.2)\nDownloading yfinance-0.2.38-py2.py3-none-any.whl (72 kB)\nDownloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\nBuilding wheels for collected packages: peewee\n  Building wheel for peewee (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for peewee: filename=peewee-3.17.6-cp310-cp310-linux_x86_64.whl size=293635 sha256=45673f2e1ce34347ae638d9997ce03ac3695f2090dd6b780df766127765814b9\n  Stored in directory: /root/.cache/pip/wheels/4b/b9/b0/83d6e258e8f963f5ff111a2cd8c483ca59372a86e6a2535212\nSuccessfully built peewee\nInstalling collected packages: peewee, multitasking, yfinance\nSuccessfully installed multitasking-0.0.11 peewee-3.17.6 yfinance-0.2.38\nCollecting finta\n  Downloading finta-1.3-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from finta) (1.26.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from finta) (2.1.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->finta) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->finta) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->finta) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->finta) (1.16.0)\nDownloading finta-1.3-py3-none-any.whl (29 kB)\nInstalling collected packages: finta\nSuccessfully installed finta-1.3\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install finta","metadata":{"execution":{"iopub.status.busy":"2024-08-04T07:13:16.317937Z","iopub.execute_input":"2024-08-04T07:13:16.318316Z","iopub.status.idle":"2024-08-04T07:13:28.814024Z","shell.execute_reply.started":"2024-08-04T07:13:16.318288Z","shell.execute_reply":"2024-08-04T07:13:28.813034Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting finta\n  Downloading finta-1.3-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from finta) (1.26.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from finta) (2.1.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->finta) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->finta) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->finta) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->finta) (1.16.0)\nDownloading finta-1.3-py3-none-any.whl (29 kB)\nInstalling collected packages: finta\nSuccessfully installed finta-1.3\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip show gym-trading-env","metadata":{"execution":{"iopub.status.busy":"2024-08-12T08:27:34.522246Z","iopub.execute_input":"2024-08-12T08:27:34.522649Z","iopub.status.idle":"2024-08-12T08:27:39.524731Z","shell.execute_reply.started":"2024-08-12T08:27:34.522616Z","shell.execute_reply":"2024-08-12T08:27:39.523661Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Name: gym-trading-env\nVersion: 0.3.3\nSummary: A simple, easy, customizable Open IA Gym environments for trading.\nHome-page: https://github.com/ClementPerroud/Gym-Trading-Env\nAuthor: \nAuthor-email: Clement Perroud <clement.perroud.pro@gmail.com>\nLicense: MIT License\n        \n        Copyright (c) [year] [fullname]\n        \n        Permission is hereby granted, free of charge, to any person obtaining a copy\n        of this software and associated documentation files (the \"Software\"), to deal\n        in the Software without restriction, including without limitation the rights\n        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n        copies of the Software, and to permit persons to whom the Software is\n        furnished to do so, subject to the following conditions:\n        \n        The above copyright notice and this permission notice shall be included in all\n        copies or substantial portions of the Software.\n        \n        THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n        SOFTWARE.\nLocation: /opt/conda/lib/python3.10/site-packages\nRequires: ccxt, flask, gymnasium, nest-asyncio, numpy, pandas, pyecharts\nRequired-by: \n","output_type":"stream"}]},{"cell_type":"code","source":"!pip show keras tensorflow scikit-learn","metadata":{"execution":{"iopub.status.busy":"2024-08-06T13:03:55.532357Z","iopub.execute_input":"2024-08-06T13:03:55.533012Z","iopub.status.idle":"2024-08-06T13:04:00.579314Z","shell.execute_reply.started":"2024-08-06T13:03:55.532984Z","shell.execute_reply":"2024-08-06T13:04:00.578217Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Name: keras\nVersion: 2.15.0\nSummary: Deep learning for humans.\nHome-page: https://keras.io/\nAuthor: Keras team\nAuthor-email: keras-users@googlegroups.com\nLicense: Apache 2.0\nLocation: /opt/conda/lib/python3.10/site-packages\nRequires: \nRequired-by: keras-tuner, tensorflow\n---\nName: tensorflow\nVersion: 2.15.0\nSummary: TensorFlow is an open source machine learning framework for everyone.\nHome-page: https://www.tensorflow.org/\nAuthor: Google Inc.\nAuthor-email: packages@tensorflow.org\nLicense: Apache 2.0\nLocation: /opt/conda/lib/python3.10/site-packages\nRequires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\nRequired-by: explainable-ai-sdk, tensorflow-cloud, tensorflow-decision-forests, tensorflow-serving-api, tensorflow-text, tf_keras, witwidget\n---\nName: scikit-learn\nVersion: 1.2.2\nSummary: A set of python modules for machine learning and data mining\nHome-page: http://scikit-learn.org\nAuthor: \nAuthor-email: \nLicense: new BSD\nLocation: /opt/conda/lib/python3.10/site-packages\nRequires: joblib, numpy, scipy, threadpoolctl\nRequired-by: bayesian-optimization, Boruta, category-encoders, cesium, eli5, esda, fastai, gplearn, hep-ml, hmmlearn, hpsklearn, hypertools, imbalanced-learn, kmapper, kmodes, librosa, lime, mapclassify, mlxtend, nilearn, pyLDAvis, pynndescent, qudida, rgf-python, scattertext, scikit-learn-intelex, scikit-optimize, scikit-plot, segregation, shap, sklearn-pandas, spopt, spreg, TPOT, tsfresh, umap-learn, vecstack, woodwork, yellowbrick\n","output_type":"stream"}]},{"cell_type":"code","source":"import gym\nimport gym_trading_env\n\nprint(\"gym-trading-env version:\", gym_trading_env.__version__)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T12:35:35.148702Z","iopub.execute_input":"2024-06-03T12:35:35.149302Z","iopub.status.idle":"2024-06-03T12:35:35.796256Z","shell.execute_reply.started":"2024-06-03T12:35:35.149270Z","shell.execute_reply":"2024-06-03T12:35:35.794997Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgym_trading_env\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgym-trading-env version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, gym_trading_env\u001b[38;5;241m.\u001b[39m__version__)\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gym_trading_env'"],"ename":"ModuleNotFoundError","evalue":"No module named 'gym_trading_env'","output_type":"error"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport gymnasium as gym\n\n\nfrom stable_baselines3 import A2C","metadata":{"executionInfo":{"elapsed":11086,"status":"ok","timestamp":1711484938822,"user":{"displayName":"Ab As","userId":"09234410323733171058"},"user_tz":-300},"id":"MmQ0jgaciCGp","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport gymnasium as gym\n\nfrom gym_trading_env.downloader import download\nimport datetime\n\n!mkdir -p /kaggle/working/data\ndownload(exchange_names = ['huobi'],\n         symbols= ['ETH/USDT'],\n         timeframe= '1h',\n         dir= '/kaggle/working/data',\n         since= datetime.datetime(year=2020, month=1, day=1),\n         #until=datetime.datetime(year=2024, month=4, day=1),\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T09:52:52.273915Z","iopub.execute_input":"2024-08-12T09:52:52.275211Z","iopub.status.idle":"2024-08-12T09:53:06.195586Z","shell.execute_reply.started":"2024-08-12T09:52:52.275171Z","shell.execute_reply":"2024-08-12T09:53:06.194543Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"ETH/USDT downloaded from huobi and stored at /kaggle/working/data/huobi-ETHUSDT-1h.pkl\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 1 h 4 h –∏ —Ç.–¥.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport yfinance as yf\n\n# –ó–∞–¥–∞–µ–º —Ç–∏–∫–µ—Ä –¥–ª—è S&P 500, –∫–æ—Ç–æ—Ä—ã–π –æ–±—ã—á–Ω–æ SPY –∏–ª–∏ ^GSPC\nticker = \"GC=F\"\n\n# –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç Ticker\nsp_data = yf.Ticker(ticker)\n\n# –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ —Å –Ω–∞—á–∞–ª–∞ 2023 –≥–æ–¥–∞ —Å —á–∞—Å–æ–≤—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º\ndata = sp_data.history(start=\"2023-01-01\", interval=\"60m\")\n\n# –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤\ndata.rename(columns={\n    'Open': 'open',\n    'High': 'high',\n    'Low': 'low',\n    'Close': 'close',\n    'Volume': 'volume'\n}, inplace=True)\n\n# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ 'date_close' —Å –∫–æ–ø–∏–µ–π –∏–Ω–¥–µ–∫—Å–∞ 'date'\ndata['date_close'] = data.index\n\n# –ü—Ä–æ—Å–º–æ—Ç—Ä –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\nprint(data.head())\n\n# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ CSV\ndata.to_csv('/kaggle/working/sp500_daily.csv', index=False)  # index=False, –µ—Å–ª–∏ –∏–Ω–¥–µ–∫—Å –Ω–µ –Ω—É–∂–µ–Ω –≤ CSV\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport yfinance as yf\n\n# –ó–∞–¥–∞–µ–º —Ç–∏–∫–µ—Ä –¥–ª—è S&P 500, –∫–æ—Ç–æ—Ä—ã–π –æ–±—ã—á–Ω–æ SPY –∏–ª–∏ ^GSPC\n#ticker = \"BTC-USD\"\n#ticker = \"^GSPC\"\nticker = \"GC=F\"\n#ticker = \"CL=F\"\n# –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç Ticker\nsp_data = yf.Ticker(ticker)\n\n# –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∑–∞ –≤–µ—Å—å –¥–æ—Å—Ç—É–ø–Ω—ã–π –ø–µ—Ä–∏–æ–¥ —Å –¥–Ω–µ–≤–Ω—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º\ndata = sp_data.history(period=\"max\", interval=\"1d\")\n#data = sp_data.history(start=\"1990-01-01\", interval=\"1d\")\n#data = sp_data.history(start=\"2023-01-01\", interval=\"60m\")\ndata.rename(columns={\n    'Open': 'open',\n    'High': 'high',\n    'Low': 'low',\n    'Close': 'close',\n    'Volume': 'volume',\n    'Dividends': 'dividends',\n    'Stock Splits': 'stock_splits',\n    'date_close': 'date_close'\n}, inplace=True)\n\n# –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤ 'dividends' –∏ 'stock_splits', –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –Ω—É–∂–Ω—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\n#data.drop(columns=['dividends', 'stock_splits'], inplace=True)\n# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ 'date_close' —Å –∫–æ–ø–∏–µ–π –∏–Ω–¥–µ–∫—Å–∞ 'date'\ndata['date_close'] = data.index\ndata.drop(columns=['dividends', 'stock_splits'], inplace=True)\n# –ü—Ä–æ—Å–º–æ—Ç—Ä –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\nprint(data.head())\n\n# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ CSV\ndata.to_csv('/kaggle/working/sp500_daily.csv', index=False)  # index=False, –µ—Å–ª–∏ –∏–Ω–¥–µ–∫—Å –Ω–µ –Ω—É–∂–µ–Ω –≤ CSV\ndata","metadata":{"execution":{"iopub.status.busy":"2024-06-16T07:22:40.668057Z","iopub.execute_input":"2024-06-16T07:22:40.668869Z","iopub.status.idle":"2024-06-16T07:22:41.986080Z","shell.execute_reply.started":"2024-06-16T07:22:40.668834Z","shell.execute_reply":"2024-06-16T07:22:41.985086Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"                                 open        high         low       close  \\\nDate                                                                        \n2000-08-30 00:00:00-04:00  273.899994  273.899994  273.899994  273.899994   \n2000-08-31 00:00:00-04:00  274.799988  278.299988  274.799988  278.299988   \n2000-09-01 00:00:00-04:00  277.000000  277.000000  277.000000  277.000000   \n2000-09-05 00:00:00-04:00  275.799988  275.799988  275.799988  275.799988   \n2000-09-06 00:00:00-04:00  274.200012  274.200012  274.200012  274.200012   \n\n                           volume                date_close  \nDate                                                         \n2000-08-30 00:00:00-04:00       0 2000-08-30 00:00:00-04:00  \n2000-08-31 00:00:00-04:00       0 2000-08-31 00:00:00-04:00  \n2000-09-01 00:00:00-04:00       0 2000-09-01 00:00:00-04:00  \n2000-09-05 00:00:00-04:00       2 2000-09-05 00:00:00-04:00  \n2000-09-06 00:00:00-04:00       0 2000-09-06 00:00:00-04:00  \n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                  open         high          low        close  \\\nDate                                                                            \n2000-08-30 00:00:00-04:00   273.899994   273.899994   273.899994   273.899994   \n2000-08-31 00:00:00-04:00   274.799988   278.299988   274.799988   278.299988   \n2000-09-01 00:00:00-04:00   277.000000   277.000000   277.000000   277.000000   \n2000-09-05 00:00:00-04:00   275.799988   275.799988   275.799988   275.799988   \n2000-09-06 00:00:00-04:00   274.200012   274.200012   274.200012   274.200012   \n...                                ...          ...          ...          ...   \n2024-06-10 00:00:00-04:00  2290.600098  2309.300049  2290.500000  2307.699951   \n2024-06-11 00:00:00-04:00  2300.000000  2314.100098  2300.000000  2307.500000   \n2024-06-12 00:00:00-04:00  2314.899902  2338.699951  2310.300049  2336.000000   \n2024-06-13 00:00:00-04:00  2309.399902  2317.699951  2296.199951  2300.199951   \n2024-06-14 00:00:00-04:00  2319.600098  2352.300049  2316.699951  2348.399902   \n\n                           volume                date_close  \nDate                                                         \n2000-08-30 00:00:00-04:00       0 2000-08-30 00:00:00-04:00  \n2000-08-31 00:00:00-04:00       0 2000-08-31 00:00:00-04:00  \n2000-09-01 00:00:00-04:00       0 2000-09-01 00:00:00-04:00  \n2000-09-05 00:00:00-04:00       2 2000-09-05 00:00:00-04:00  \n2000-09-06 00:00:00-04:00       0 2000-09-06 00:00:00-04:00  \n...                           ...                       ...  \n2024-06-10 00:00:00-04:00      69 2024-06-10 00:00:00-04:00  \n2024-06-11 00:00:00-04:00     871 2024-06-11 00:00:00-04:00  \n2024-06-12 00:00:00-04:00     132 2024-06-12 00:00:00-04:00  \n2024-06-13 00:00:00-04:00     298 2024-06-13 00:00:00-04:00  \n2024-06-14 00:00:00-04:00  155486 2024-06-14 00:00:00-04:00  \n\n[5970 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>date_close</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2000-08-30 00:00:00-04:00</th>\n      <td>273.899994</td>\n      <td>273.899994</td>\n      <td>273.899994</td>\n      <td>273.899994</td>\n      <td>0</td>\n      <td>2000-08-30 00:00:00-04:00</td>\n    </tr>\n    <tr>\n      <th>2000-08-31 00:00:00-04:00</th>\n      <td>274.799988</td>\n      <td>278.299988</td>\n      <td>274.799988</td>\n      <td>278.299988</td>\n      <td>0</td>\n      <td>2000-08-31 00:00:00-04:00</td>\n    </tr>\n    <tr>\n      <th>2000-09-01 00:00:00-04:00</th>\n      <td>277.000000</td>\n      <td>277.000000</td>\n      <td>277.000000</td>\n      <td>277.000000</td>\n      <td>0</td>\n      <td>2000-09-01 00:00:00-04:00</td>\n    </tr>\n    <tr>\n      <th>2000-09-05 00:00:00-04:00</th>\n      <td>275.799988</td>\n      <td>275.799988</td>\n      <td>275.799988</td>\n      <td>275.799988</td>\n      <td>2</td>\n      <td>2000-09-05 00:00:00-04:00</td>\n    </tr>\n    <tr>\n      <th>2000-09-06 00:00:00-04:00</th>\n      <td>274.200012</td>\n      <td>274.200012</td>\n      <td>274.200012</td>\n      <td>274.200012</td>\n      <td>0</td>\n      <td>2000-09-06 00:00:00-04:00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2024-06-10 00:00:00-04:00</th>\n      <td>2290.600098</td>\n      <td>2309.300049</td>\n      <td>2290.500000</td>\n      <td>2307.699951</td>\n      <td>69</td>\n      <td>2024-06-10 00:00:00-04:00</td>\n    </tr>\n    <tr>\n      <th>2024-06-11 00:00:00-04:00</th>\n      <td>2300.000000</td>\n      <td>2314.100098</td>\n      <td>2300.000000</td>\n      <td>2307.500000</td>\n      <td>871</td>\n      <td>2024-06-11 00:00:00-04:00</td>\n    </tr>\n    <tr>\n      <th>2024-06-12 00:00:00-04:00</th>\n      <td>2314.899902</td>\n      <td>2338.699951</td>\n      <td>2310.300049</td>\n      <td>2336.000000</td>\n      <td>132</td>\n      <td>2024-06-12 00:00:00-04:00</td>\n    </tr>\n    <tr>\n      <th>2024-06-13 00:00:00-04:00</th>\n      <td>2309.399902</td>\n      <td>2317.699951</td>\n      <td>2296.199951</td>\n      <td>2300.199951</td>\n      <td>298</td>\n      <td>2024-06-13 00:00:00-04:00</td>\n    </tr>\n    <tr>\n      <th>2024-06-14 00:00:00-04:00</th>\n      <td>2319.600098</td>\n      <td>2352.300049</td>\n      <td>2316.699951</td>\n      <td>2348.399902</td>\n      <td>155486</td>\n      <td>2024-06-14 00:00:00-04:00</td>\n    </tr>\n  </tbody>\n</table>\n<p>5970 rows √ó 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport yfinance as yf\n\n# –ó–∞–¥–∞–µ–º —Ç–∏–∫–µ—Ä –¥–ª—è S&P 500, –∫–æ—Ç–æ—Ä—ã–π –æ–±—ã—á–Ω–æ SPY –∏–ª–∏ ^GSPC\n#ticker = \"^GSPC\"\n#ticker = \"^SPY\"\n# –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç Ticker\nsp_data = yf.Ticker(ticker)\n\n# –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∑–∞ –≤–µ—Å—å –¥–æ—Å—Ç—É–ø–Ω—ã–π –ø–µ—Ä–∏–æ–¥ —Å –¥–Ω–µ–≤–Ω—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º\ndata = sp_data.history(period=\"max\", interval=\"60m\")\n\ndata.rename(columns={\n    'Open': 'open',\n    'High': 'high',\n    'Low': 'low',\n    'Close': 'close',\n    'Volume': 'volume',\n    'date_close': 'date_close'\n}, inplace=True)\n\n# –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤ 'dividends' –∏ 'stock_splits', –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –Ω—É–∂–Ω—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\n#data.drop(columns=['dividends', 'stock_splits'], inplace=True)\n# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ 'date_close' —Å –∫–æ–ø–∏–µ–π –∏–Ω–¥–µ–∫—Å–∞ 'date'\ndata['date_close'] = data.index\n\n# –ü—Ä–æ—Å–º–æ—Ç—Ä –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\nprint(data.head())\n\n# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ CSV\ndata.to_csv('/kaggle/working/sp500_daily.csv', index=False)  # index=False, –µ—Å–ª–∏ –∏–Ω–¥–µ–∫—Å –Ω–µ –Ω—É–∂–µ–Ω –≤ CSV\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å MACD + RSI –Ω–∞ 9 –≤—Ö–æ–¥–æ–≤","metadata":{}},{"cell_type":"code","source":"\n\nimport pandas as pd\nfrom finta import TA\n\n# –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É\n#file_path = '/kaggle/working/sp500_daily.csv'\nfile_path = '/kaggle/working/data/huobi-ETHUSDT-1h.pkl'\n# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞\ndata = pd.read_pickle(file_path)\n#data = pd.read_csv(file_path)\ndata.dropna(inplace=True)  # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏\n\n# –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏ Finta\ndata.columns = ['open', 'high', 'low', 'close', 'volume', 'date_close']\n\n# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å—Ç–æ–ª–±—Ü–∞ –¥–∞—Ç—ã –æ—Ç–∫—Ä—ã—Ç–∏—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∏–Ω–¥–µ–∫—Å–∞\ndata.index = pd.to_datetime(data['date_close'], utc=True)\ndata.drop(columns=['date_close'], inplace=True)  # –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–Ω—É–∂–Ω–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞\n\n# –£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∑–æ–Ω—ã\ndata.index = data.index.tz_localize(None)\n\n\n# –†–∞—Å—á–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤\ndata['obv'] = TA.OBV(data)\ndata['mfi'] = TA.MFI(data)\nbollinger = TA.BBANDS(data)\ndata['bollinger_upper'] = bollinger['BB_UPPER']\ndata['bollinger_middle'] = bollinger['BB_MIDDLE']\ndata['bollinger_lower'] = bollinger['BB_LOWER']\ndata['roc'] = TA.ROC(data)\n\n# –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–∏–π –æ—Å—Ü–∏–ª–ª—è—Ç–æ—Ä –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ DataFrame\ndata['stoch_k'] = TA.STOCH(data)\ndata['stoch_d'] = TA.STOCHD(data)\ndata['vwap'] = TA.VWAP(data)\n\nmacd_values = TA.MACD(data)\ndata['macd'] = macd_values['MACD']\ndata['macd_signal'] = macd_values['SIGNAL']\ndata['macd_hist'] = macd_values['MACD'] - macd_values['SIGNAL']\n\ndata['rsi'] = TA.RSI(data)\n\nfpp = TA.PIVOT_FIB(data)\ndata['pivot'] = fpp['pivot']\ndata['s1'] = fpp['s1']\ndata['s2'] = fpp['s2']\ndata['s3'] = fpp['s3']\ndata['r1'] = fpp['r1']\ndata['r2'] = fpp['r2']\ndata['r3'] = fpp['r3']\ndata.dropna(inplace=True)\ndata","metadata":{"execution":{"iopub.status.busy":"2024-08-12T09:53:35.007273Z","iopub.execute_input":"2024-08-12T09:53:35.007676Z","iopub.status.idle":"2024-08-12T09:53:36.359891Z","shell.execute_reply.started":"2024-08-12T09:53:35.007643Z","shell.execute_reply":"2024-08-12T09:53:36.358928Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                        open     high      low    close        volume  \\\ndate_close                                                              \n2020-01-01 21:00:00   131.88   132.24   131.68   132.15   6486.249190   \n2020-01-01 22:00:00   132.17   132.35   131.66   131.78   7816.579777   \n2020-01-01 23:00:00   131.79   131.79   129.94   130.30  20002.611452   \n2020-01-02 00:00:00   130.31   130.84   129.72   130.69   9964.581162   \n2020-01-02 01:00:00   130.68   130.74   130.24   130.64   7074.222738   \n...                      ...      ...      ...      ...           ...   \n2024-08-12 06:00:00  2538.94  2554.82  2535.23  2553.95    758.606686   \n2024-08-12 07:00:00  2553.79  2561.99  2541.83  2552.70    605.874441   \n2024-08-12 08:00:00  2552.31  2582.81  2516.07  2568.33   1746.793670   \n2024-08-12 09:00:00  2567.43  2596.90  2558.72  2563.19   1395.693586   \n2024-08-12 10:00:00  2563.33  2593.86  2562.69  2584.92   1447.627359   \n\n                              obv        mfi  bollinger_upper  \\\ndate_close                                                      \n2020-01-01 21:00:00  6.983973e+04  75.703253       132.917368   \n2020-01-01 22:00:00  6.202315e+04  75.384501       132.976830   \n2020-01-01 23:00:00  4.202054e+04  68.772269       132.990392   \n2020-01-02 00:00:00  5.198512e+04  62.935442       132.968535   \n2020-01-02 01:00:00  4.491090e+04  63.200834       132.947149   \n...                           ...        ...              ...   \n2024-08-12 06:00:00  5.954733e+06  40.998622      2682.768184   \n2024-08-12 07:00:00  5.954127e+06  40.578154      2669.444824   \n2024-08-12 08:00:00  5.955874e+06  42.046855      2659.433666   \n2024-08-12 09:00:00  5.954478e+06  46.137371      2651.568823   \n2024-08-12 10:00:00  5.955926e+06  56.379144      2643.568593   \n\n                     bollinger_middle  bollinger_lower  ...  macd_signal  \\\ndate_close                                              ...                \n2020-01-01 21:00:00          131.1635       129.409632  ...     0.235575   \n2020-01-01 22:00:00          131.2205       129.464170  ...     0.242430   \n2020-01-01 23:00:00          131.1925       129.394608  ...     0.222974   \n2020-01-02 00:00:00          131.2185       129.468465  ...     0.193149   \n2020-01-02 01:00:00          131.2405       129.533851  ...     0.157382   \n...                               ...              ...  ...          ...   \n2024-08-12 06:00:00         2593.5910      2504.413816  ...   -18.122919   \n2024-08-12 07:00:00         2587.4395      2505.434176  ...   -19.097774   \n2024-08-12 08:00:00         2583.1915      2506.949334  ...   -19.463737   \n2024-08-12 09:00:00         2579.4435      2507.318177  ...   -19.466518   \n2024-08-12 10:00:00         2576.7935      2510.018407  ...   -18.850460   \n\n                     macd_hist        rsi        pivot           s1  \\\ndate_close                                                            \n2020-01-01 21:00:00   0.061309  64.528279   131.920000   131.698440   \n2020-01-01 22:00:00   0.027101  57.417357   132.023333   131.809413   \n2020-01-01 23:00:00  -0.077105  38.934904   131.930000   131.666420   \n2020-01-02 00:00:00  -0.118420  44.046228   130.676667   129.969967   \n2020-01-02 01:00:00  -0.142224  43.543018   130.416667   129.988827   \n...                        ...        ...          ...          ...   \n2024-08-12 06:00:00  -5.589920  38.929251  2541.913333  2535.461353   \n2024-08-12 07:00:00  -3.899420  38.636204  2548.000000  2540.516620   \n2024-08-12 08:00:00  -1.463852  44.283942  2552.173333  2544.472213   \n2024-08-12 09:00:00  -0.011124  42.886070  2555.736667  2530.241987   \n2024-08-12 10:00:00   2.464232  50.062800  2572.936667  2558.351907   \n\n                              s2           s3           r1           r2  \\\ndate_close                                                                \n2020-01-01 21:00:00   131.561560   131.340000   132.141560   132.278440   \n2020-01-01 22:00:00   131.677253   131.463333   132.237253   132.369413   \n2020-01-01 23:00:00   131.503580   131.240000   132.193580   132.356420   \n2020-01-02 00:00:00   129.533367   128.826667   131.383367   131.819967   \n2020-01-02 01:00:00   129.724507   129.296667   130.844507   131.108827   \n...                          ...          ...          ...          ...   \n2024-08-12 06:00:00  2531.475313  2525.023333  2548.365313  2552.351353   \n2024-08-12 07:00:00  2535.893380  2528.410000  2555.483380  2560.106620   \n2024-08-12 08:00:00  2539.714453  2532.013333  2559.874453  2564.632213   \n2024-08-12 09:00:00  2514.491347  2488.996667  2581.231347  2596.981987   \n2024-08-12 10:00:00  2549.341427  2534.756667  2587.521427  2596.531907   \n\n                              r3  \ndate_close                        \n2020-01-01 21:00:00   132.500000  \n2020-01-01 22:00:00   132.583333  \n2020-01-01 23:00:00   132.620000  \n2020-01-02 00:00:00   132.526667  \n2020-01-02 01:00:00   131.536667  \n...                          ...  \n2024-08-12 06:00:00  2558.803333  \n2024-08-12 07:00:00  2567.590000  \n2024-08-12 08:00:00  2572.333333  \n2024-08-12 09:00:00  2622.476667  \n2024-08-12 10:00:00  2611.116667  \n\n[40382 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>obv</th>\n      <th>mfi</th>\n      <th>bollinger_upper</th>\n      <th>bollinger_middle</th>\n      <th>bollinger_lower</th>\n      <th>...</th>\n      <th>macd_signal</th>\n      <th>macd_hist</th>\n      <th>rsi</th>\n      <th>pivot</th>\n      <th>s1</th>\n      <th>s2</th>\n      <th>s3</th>\n      <th>r1</th>\n      <th>r2</th>\n      <th>r3</th>\n    </tr>\n    <tr>\n      <th>date_close</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2020-01-01 21:00:00</th>\n      <td>131.88</td>\n      <td>132.24</td>\n      <td>131.68</td>\n      <td>132.15</td>\n      <td>6486.249190</td>\n      <td>6.983973e+04</td>\n      <td>75.703253</td>\n      <td>132.917368</td>\n      <td>131.1635</td>\n      <td>129.409632</td>\n      <td>...</td>\n      <td>0.235575</td>\n      <td>0.061309</td>\n      <td>64.528279</td>\n      <td>131.920000</td>\n      <td>131.698440</td>\n      <td>131.561560</td>\n      <td>131.340000</td>\n      <td>132.141560</td>\n      <td>132.278440</td>\n      <td>132.500000</td>\n    </tr>\n    <tr>\n      <th>2020-01-01 22:00:00</th>\n      <td>132.17</td>\n      <td>132.35</td>\n      <td>131.66</td>\n      <td>131.78</td>\n      <td>7816.579777</td>\n      <td>6.202315e+04</td>\n      <td>75.384501</td>\n      <td>132.976830</td>\n      <td>131.2205</td>\n      <td>129.464170</td>\n      <td>...</td>\n      <td>0.242430</td>\n      <td>0.027101</td>\n      <td>57.417357</td>\n      <td>132.023333</td>\n      <td>131.809413</td>\n      <td>131.677253</td>\n      <td>131.463333</td>\n      <td>132.237253</td>\n      <td>132.369413</td>\n      <td>132.583333</td>\n    </tr>\n    <tr>\n      <th>2020-01-01 23:00:00</th>\n      <td>131.79</td>\n      <td>131.79</td>\n      <td>129.94</td>\n      <td>130.30</td>\n      <td>20002.611452</td>\n      <td>4.202054e+04</td>\n      <td>68.772269</td>\n      <td>132.990392</td>\n      <td>131.1925</td>\n      <td>129.394608</td>\n      <td>...</td>\n      <td>0.222974</td>\n      <td>-0.077105</td>\n      <td>38.934904</td>\n      <td>131.930000</td>\n      <td>131.666420</td>\n      <td>131.503580</td>\n      <td>131.240000</td>\n      <td>132.193580</td>\n      <td>132.356420</td>\n      <td>132.620000</td>\n    </tr>\n    <tr>\n      <th>2020-01-02 00:00:00</th>\n      <td>130.31</td>\n      <td>130.84</td>\n      <td>129.72</td>\n      <td>130.69</td>\n      <td>9964.581162</td>\n      <td>5.198512e+04</td>\n      <td>62.935442</td>\n      <td>132.968535</td>\n      <td>131.2185</td>\n      <td>129.468465</td>\n      <td>...</td>\n      <td>0.193149</td>\n      <td>-0.118420</td>\n      <td>44.046228</td>\n      <td>130.676667</td>\n      <td>129.969967</td>\n      <td>129.533367</td>\n      <td>128.826667</td>\n      <td>131.383367</td>\n      <td>131.819967</td>\n      <td>132.526667</td>\n    </tr>\n    <tr>\n      <th>2020-01-02 01:00:00</th>\n      <td>130.68</td>\n      <td>130.74</td>\n      <td>130.24</td>\n      <td>130.64</td>\n      <td>7074.222738</td>\n      <td>4.491090e+04</td>\n      <td>63.200834</td>\n      <td>132.947149</td>\n      <td>131.2405</td>\n      <td>129.533851</td>\n      <td>...</td>\n      <td>0.157382</td>\n      <td>-0.142224</td>\n      <td>43.543018</td>\n      <td>130.416667</td>\n      <td>129.988827</td>\n      <td>129.724507</td>\n      <td>129.296667</td>\n      <td>130.844507</td>\n      <td>131.108827</td>\n      <td>131.536667</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2024-08-12 06:00:00</th>\n      <td>2538.94</td>\n      <td>2554.82</td>\n      <td>2535.23</td>\n      <td>2553.95</td>\n      <td>758.606686</td>\n      <td>5.954733e+06</td>\n      <td>40.998622</td>\n      <td>2682.768184</td>\n      <td>2593.5910</td>\n      <td>2504.413816</td>\n      <td>...</td>\n      <td>-18.122919</td>\n      <td>-5.589920</td>\n      <td>38.929251</td>\n      <td>2541.913333</td>\n      <td>2535.461353</td>\n      <td>2531.475313</td>\n      <td>2525.023333</td>\n      <td>2548.365313</td>\n      <td>2552.351353</td>\n      <td>2558.803333</td>\n    </tr>\n    <tr>\n      <th>2024-08-12 07:00:00</th>\n      <td>2553.79</td>\n      <td>2561.99</td>\n      <td>2541.83</td>\n      <td>2552.70</td>\n      <td>605.874441</td>\n      <td>5.954127e+06</td>\n      <td>40.578154</td>\n      <td>2669.444824</td>\n      <td>2587.4395</td>\n      <td>2505.434176</td>\n      <td>...</td>\n      <td>-19.097774</td>\n      <td>-3.899420</td>\n      <td>38.636204</td>\n      <td>2548.000000</td>\n      <td>2540.516620</td>\n      <td>2535.893380</td>\n      <td>2528.410000</td>\n      <td>2555.483380</td>\n      <td>2560.106620</td>\n      <td>2567.590000</td>\n    </tr>\n    <tr>\n      <th>2024-08-12 08:00:00</th>\n      <td>2552.31</td>\n      <td>2582.81</td>\n      <td>2516.07</td>\n      <td>2568.33</td>\n      <td>1746.793670</td>\n      <td>5.955874e+06</td>\n      <td>42.046855</td>\n      <td>2659.433666</td>\n      <td>2583.1915</td>\n      <td>2506.949334</td>\n      <td>...</td>\n      <td>-19.463737</td>\n      <td>-1.463852</td>\n      <td>44.283942</td>\n      <td>2552.173333</td>\n      <td>2544.472213</td>\n      <td>2539.714453</td>\n      <td>2532.013333</td>\n      <td>2559.874453</td>\n      <td>2564.632213</td>\n      <td>2572.333333</td>\n    </tr>\n    <tr>\n      <th>2024-08-12 09:00:00</th>\n      <td>2567.43</td>\n      <td>2596.90</td>\n      <td>2558.72</td>\n      <td>2563.19</td>\n      <td>1395.693586</td>\n      <td>5.954478e+06</td>\n      <td>46.137371</td>\n      <td>2651.568823</td>\n      <td>2579.4435</td>\n      <td>2507.318177</td>\n      <td>...</td>\n      <td>-19.466518</td>\n      <td>-0.011124</td>\n      <td>42.886070</td>\n      <td>2555.736667</td>\n      <td>2530.241987</td>\n      <td>2514.491347</td>\n      <td>2488.996667</td>\n      <td>2581.231347</td>\n      <td>2596.981987</td>\n      <td>2622.476667</td>\n    </tr>\n    <tr>\n      <th>2024-08-12 10:00:00</th>\n      <td>2563.33</td>\n      <td>2593.86</td>\n      <td>2562.69</td>\n      <td>2584.92</td>\n      <td>1447.627359</td>\n      <td>5.955926e+06</td>\n      <td>56.379144</td>\n      <td>2643.568593</td>\n      <td>2576.7935</td>\n      <td>2510.018407</td>\n      <td>...</td>\n      <td>-18.850460</td>\n      <td>2.464232</td>\n      <td>50.062800</td>\n      <td>2572.936667</td>\n      <td>2558.351907</td>\n      <td>2549.341427</td>\n      <td>2534.756667</td>\n      <td>2587.521427</td>\n      <td>2596.531907</td>\n      <td>2611.116667</td>\n    </tr>\n  </tbody>\n</table>\n<p>40382 rows √ó 25 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –î–ê–¢–ê–°–ï–¢–ê —Å MACD + RSI + FIB(FPP)","metadata":{}},{"cell_type":"code","source":"\n\n# –°–Ω–∞—á–∞–ª–∞ —É–±–µ–¥–∏–º—Å—è, —á—Ç–æ –Ω–µ—Ç –Ω—É–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ —Å—Ç–æ–ª–±—Ü–µ volume, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å\n#data = data[data['volume'] != 0]\ndata = data[(data['volume'] != 0) & (data['rsi'] != 0)]\n\n# –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö c –§–ò–ë–ê–ù–ê–ß–ß–ò\n#features = ['open', 'high', 'low', 'close', 'volume', 'macd', 'macd_signal', 'macd_hist', 'rsi', 'pivot', 's1', 's2', 's3', 'r1', 'r2', 'r3']\n# –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n#features = ['open', 'high', 'low', 'close', 'volume', 'macd', 'macd_signal', 'macd_hist', 'rsi', 'pivot', 's1', 's2', 's3', 'r1', 'r2', 'r3', 'obv', 'mfi', 'bollinger_upper', 'bollinger_middle', 'bollinger_lower', 'roc', 'stoch_k', 'stoch_d', 'vwap']\n#features = ['open', 'high', 'low', 'close', 'volume', 'macd', 'macd_signal', 'macd_hist', 'rsi', 'pivot', 's1', 's2', 's3', 'r1', 'r2', 'r3', 'obv', 'mfi', 'roc', 'stoch_k', 'stoch_d', 'vwap']\n# –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n#features = ['open', 'high', 'low', 'close', 'volume', 'macd', 'macd_signal', 'macd_hist', 'rsi'] #–ë–ï–ó –§–ò–ë–û–ù–ê–ß–ß–ò\n#features = ['open', 'high', 'low', 'close', 'volume', 'macd', 'macd_signal', 'macd_hist', 'rsi', 'obv', 'mfi', 'roc', 'vwap']\nfeatures = ['open', 'high', 'low', 'close', 'volume', 'macd_signal', 'macd_hist', 'rsi', 'mfi', 'roc', 'stoch_d']\n#–û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–æ—á–∫—É —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏ (99% –æ—Ç –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö)\nsplit_index = int(len(data) * 0.8)\n\n# –°–æ–∑–¥–∞–µ–º –æ–±—É—á–∞—é—â—É—é –≤—ã–±–æ—Ä–∫—É\ndata_train = data[features].iloc[:split_index]\n\n# –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫—É\ndata_test = data[features].iloc[split_index:]\n\n# –ü–µ—á–∞—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\nprint(data_train.head())\n\n# –ü–µ—á–∞—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\nprint(data_test.head())\ndata_train","metadata":{"execution":{"iopub.status.busy":"2024-08-12T08:28:34.799508Z","iopub.execute_input":"2024-08-12T08:28:34.800521Z","iopub.status.idle":"2024-08-12T08:28:34.852680Z","shell.execute_reply.started":"2024-08-12T08:28:34.800476Z","shell.execute_reply":"2024-08-12T08:28:34.851615Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"                       open    high     low   close        volume  \\\ndate_close                                                          \n2020-01-01 21:00:00  131.88  132.24  131.68  132.15   6486.249190   \n2020-01-01 22:00:00  132.17  132.35  131.66  131.78   7816.579777   \n2020-01-01 23:00:00  131.79  131.79  129.94  130.30  20002.611452   \n2020-01-02 00:00:00  130.31  130.84  129.72  130.69   9964.581162   \n2020-01-02 01:00:00  130.68  130.74  130.24  130.64   7074.222738   \n\n                     macd_signal  macd_hist        rsi        mfi       roc  \\\ndate_close                                                                    \n2020-01-01 21:00:00     0.235575   0.061309  64.528279  75.703253  1.373121   \n2020-01-01 22:00:00     0.242430   0.027101  57.417357  75.384501  1.244622   \n2020-01-01 23:00:00     0.222974  -0.077105  38.934904  68.772269 -0.290787   \n2020-01-02 00:00:00     0.193149  -0.118420  44.046228  62.935442 -0.030597   \n2020-01-02 01:00:00     0.157382  -0.142224  43.543018  63.200834 -0.699301   \n\n                       stoch_d  \ndate_close                      \n2020-01-01 21:00:00  68.789809  \n2020-01-01 22:00:00  66.135881  \n2020-01-01 23:00:00  48.613713  \n2020-01-02 00:00:00  34.161458  \n2020-01-02 01:00:00  23.128886  \n                        open     high      low    close       volume  \\\ndate_close                                                             \n2023-09-10 17:00:00  1619.57  1619.97  1598.31  1613.58  1544.241441   \n2023-09-10 18:00:00  1613.40  1613.67  1602.01  1608.53   692.852104   \n2023-09-10 19:00:00  1608.49  1614.11  1608.01  1612.32   232.175314   \n2023-09-10 20:00:00  1612.32  1619.66  1601.77  1616.94   635.332900   \n2023-09-10 21:00:00  1616.99  1626.31  1614.42  1619.06   536.032442   \n\n                     macd_signal  macd_hist        rsi        mfi       roc  \\\ndate_close                                                                    \n2023-09-10 17:00:00    -2.717747  -0.946417  25.119042  18.619474 -0.738809   \n2023-09-10 18:00:00    -3.086625  -1.475510  21.166320  14.802293 -1.065289   \n2023-09-10 19:00:00    -3.451569  -1.459778  30.061269  21.004728 -0.896183   \n2023-09-10 20:00:00    -3.713341  -1.047088  39.084225  31.157105 -0.485589   \n2023-09-10 21:00:00    -3.854437  -0.564385  42.735110  36.874782 -0.393122   \n\n                       stoch_d  \ndate_close                      \n2023-09-10 17:00:00  36.595680  \n2023-09-10 18:00:00  38.495216  \n2023-09-10 19:00:00  40.987925  \n2023-09-10 20:00:00  46.340926  \n2023-09-10 21:00:00  58.909853  \n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                        open     high      low    close        volume  \\\ndate_close                                                              \n2020-01-01 21:00:00   131.88   132.24   131.68   132.15   6486.249190   \n2020-01-01 22:00:00   132.17   132.35   131.66   131.78   7816.579777   \n2020-01-01 23:00:00   131.79   131.79   129.94   130.30  20002.611452   \n2020-01-02 00:00:00   130.31   130.84   129.72   130.69   9964.581162   \n2020-01-02 01:00:00   130.68   130.74   130.24   130.64   7074.222738   \n...                      ...      ...      ...      ...           ...   \n2023-09-10 12:00:00  1622.13  1626.53  1619.71  1624.43    272.258384   \n2023-09-10 13:00:00  1624.43  1626.68  1624.27  1625.86    179.993519   \n2023-09-10 14:00:00  1625.94  1628.52  1623.87  1627.01    244.913376   \n2023-09-10 15:00:00  1626.91  1627.41  1620.93  1621.92    188.575160   \n2023-09-10 16:00:00  1622.18  1622.18  1611.84  1619.60    617.901676   \n\n                     macd_signal  macd_hist        rsi        mfi       roc  \\\ndate_close                                                                    \n2020-01-01 21:00:00     0.235575   0.061309  64.528279  75.703253  1.373121   \n2020-01-01 22:00:00     0.242430   0.027101  57.417357  75.384501  1.244622   \n2020-01-01 23:00:00     0.222974  -0.077105  38.934904  68.772269 -0.290787   \n2020-01-02 00:00:00     0.193149  -0.118420  44.046228  62.935442 -0.030597   \n2020-01-02 01:00:00     0.157382  -0.142224  43.543018  63.200834 -0.699301   \n...                          ...        ...        ...        ...       ...   \n2023-09-10 12:00:00    -2.103088  -0.761932  36.577936  23.165199 -0.673821   \n2023-09-10 13:00:00    -2.226275  -0.492746  40.889605  26.128397 -0.378667   \n2023-09-10 14:00:00    -2.277402  -0.204509  44.176377  32.869750 -0.253809   \n2023-09-10 15:00:00    -2.356701  -0.317195  34.920952  32.759437 -0.554885   \n2023-09-10 16:00:00    -2.481143  -0.497769  31.664574  29.636276 -0.720871   \n\n                       stoch_d  \ndate_close                      \n2020-01-01 21:00:00  68.789809  \n2020-01-01 22:00:00  66.135881  \n2020-01-01 23:00:00  48.613713  \n2020-01-02 00:00:00  34.161458  \n2020-01-02 01:00:00  23.128886  \n...                        ...  \n2023-09-10 12:00:00  25.529243  \n2023-09-10 13:00:00  30.848930  \n2023-09-10 14:00:00  40.819801  \n2023-09-10 15:00:00  38.679710  \n2023-09-10 16:00:00  37.750241  \n\n[32304 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>macd_signal</th>\n      <th>macd_hist</th>\n      <th>rsi</th>\n      <th>mfi</th>\n      <th>roc</th>\n      <th>stoch_d</th>\n    </tr>\n    <tr>\n      <th>date_close</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2020-01-01 21:00:00</th>\n      <td>131.88</td>\n      <td>132.24</td>\n      <td>131.68</td>\n      <td>132.15</td>\n      <td>6486.249190</td>\n      <td>0.235575</td>\n      <td>0.061309</td>\n      <td>64.528279</td>\n      <td>75.703253</td>\n      <td>1.373121</td>\n      <td>68.789809</td>\n    </tr>\n    <tr>\n      <th>2020-01-01 22:00:00</th>\n      <td>132.17</td>\n      <td>132.35</td>\n      <td>131.66</td>\n      <td>131.78</td>\n      <td>7816.579777</td>\n      <td>0.242430</td>\n      <td>0.027101</td>\n      <td>57.417357</td>\n      <td>75.384501</td>\n      <td>1.244622</td>\n      <td>66.135881</td>\n    </tr>\n    <tr>\n      <th>2020-01-01 23:00:00</th>\n      <td>131.79</td>\n      <td>131.79</td>\n      <td>129.94</td>\n      <td>130.30</td>\n      <td>20002.611452</td>\n      <td>0.222974</td>\n      <td>-0.077105</td>\n      <td>38.934904</td>\n      <td>68.772269</td>\n      <td>-0.290787</td>\n      <td>48.613713</td>\n    </tr>\n    <tr>\n      <th>2020-01-02 00:00:00</th>\n      <td>130.31</td>\n      <td>130.84</td>\n      <td>129.72</td>\n      <td>130.69</td>\n      <td>9964.581162</td>\n      <td>0.193149</td>\n      <td>-0.118420</td>\n      <td>44.046228</td>\n      <td>62.935442</td>\n      <td>-0.030597</td>\n      <td>34.161458</td>\n    </tr>\n    <tr>\n      <th>2020-01-02 01:00:00</th>\n      <td>130.68</td>\n      <td>130.74</td>\n      <td>130.24</td>\n      <td>130.64</td>\n      <td>7074.222738</td>\n      <td>0.157382</td>\n      <td>-0.142224</td>\n      <td>43.543018</td>\n      <td>63.200834</td>\n      <td>-0.699301</td>\n      <td>23.128886</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2023-09-10 12:00:00</th>\n      <td>1622.13</td>\n      <td>1626.53</td>\n      <td>1619.71</td>\n      <td>1624.43</td>\n      <td>272.258384</td>\n      <td>-2.103088</td>\n      <td>-0.761932</td>\n      <td>36.577936</td>\n      <td>23.165199</td>\n      <td>-0.673821</td>\n      <td>25.529243</td>\n    </tr>\n    <tr>\n      <th>2023-09-10 13:00:00</th>\n      <td>1624.43</td>\n      <td>1626.68</td>\n      <td>1624.27</td>\n      <td>1625.86</td>\n      <td>179.993519</td>\n      <td>-2.226275</td>\n      <td>-0.492746</td>\n      <td>40.889605</td>\n      <td>26.128397</td>\n      <td>-0.378667</td>\n      <td>30.848930</td>\n    </tr>\n    <tr>\n      <th>2023-09-10 14:00:00</th>\n      <td>1625.94</td>\n      <td>1628.52</td>\n      <td>1623.87</td>\n      <td>1627.01</td>\n      <td>244.913376</td>\n      <td>-2.277402</td>\n      <td>-0.204509</td>\n      <td>44.176377</td>\n      <td>32.869750</td>\n      <td>-0.253809</td>\n      <td>40.819801</td>\n    </tr>\n    <tr>\n      <th>2023-09-10 15:00:00</th>\n      <td>1626.91</td>\n      <td>1627.41</td>\n      <td>1620.93</td>\n      <td>1621.92</td>\n      <td>188.575160</td>\n      <td>-2.356701</td>\n      <td>-0.317195</td>\n      <td>34.920952</td>\n      <td>32.759437</td>\n      <td>-0.554885</td>\n      <td>38.679710</td>\n    </tr>\n    <tr>\n      <th>2023-09-10 16:00:00</th>\n      <td>1622.18</td>\n      <td>1622.18</td>\n      <td>1611.84</td>\n      <td>1619.60</td>\n      <td>617.901676</td>\n      <td>-2.481143</td>\n      <td>-0.497769</td>\n      <td>31.664574</td>\n      <td>29.636276</td>\n      <td>-0.720871</td>\n      <td>37.750241</td>\n    </tr>\n  </tbody>\n</table>\n<p>32304 rows √ó 11 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data_train","metadata":{"execution":{"iopub.status.busy":"2024-08-06T13:21:49.556183Z","iopub.execute_input":"2024-08-06T13:21:49.556951Z","iopub.status.idle":"2024-08-06T13:21:49.577330Z","shell.execute_reply.started":"2024-08-06T13:21:49.556919Z","shell.execute_reply":"2024-08-06T13:21:49.576435Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                        open     high      low    close        volume  \\\ndate_close                                                              \n2020-01-01 21:00:00   131.88   132.24   131.68   132.15   6486.249190   \n2020-01-01 22:00:00   132.17   132.35   131.66   131.78   7816.579777   \n2020-01-01 23:00:00   131.79   131.79   129.94   130.30  20002.611452   \n2020-01-02 00:00:00   130.31   130.84   129.72   130.69   9964.581162   \n2020-01-02 01:00:00   130.68   130.74   130.24   130.64   7074.222738   \n...                      ...      ...      ...      ...           ...   \n2023-09-05 19:00:00  1636.21  1637.81  1633.44  1636.64    197.037785   \n2023-09-05 20:00:00  1636.65  1639.21  1631.98  1632.36    239.310545   \n2023-09-05 21:00:00  1632.36  1633.61  1626.93  1629.93    561.978536   \n2023-09-05 22:00:00  1629.78  1633.55  1629.73  1630.50     68.132906   \n2023-09-05 23:00:00  1630.90  1632.00  1629.88  1631.88     63.297790   \n\n                     macd_signal  macd_hist        rsi        mfi       roc  \\\ndate_close                                                                    \n2020-01-01 21:00:00     0.235575   0.061309  64.528279  75.703253  1.373121   \n2020-01-01 22:00:00     0.242430   0.027101  57.417357  75.384501  1.244622   \n2020-01-01 23:00:00     0.222974  -0.077105  38.934904  68.772269 -0.290787   \n2020-01-02 00:00:00     0.193149  -0.118420  44.046228  62.935442 -0.030597   \n2020-01-02 01:00:00     0.157382  -0.142224  43.543018  63.200834 -0.699301   \n...                          ...        ...        ...        ...       ...   \n2023-09-05 19:00:00     0.578337   1.253726  57.699871  69.530462  0.915033   \n2023-09-05 20:00:00     0.789990   0.846612  51.415045  64.067680  0.459105   \n2023-09-05 21:00:00     0.886185   0.384782  48.204677  59.749397  0.337345   \n2023-09-05 22:00:00     0.912046   0.103441  49.008965  58.781891 -0.107214   \n2023-09-05 23:00:00     0.912404   0.001433  50.993083  55.078108 -0.101620   \n\n                       stoch_d  \ndate_close                      \n2020-01-01 21:00:00  68.789809  \n2020-01-01 22:00:00  66.135881  \n2020-01-01 23:00:00  48.613713  \n2020-01-02 00:00:00  34.161458  \n2020-01-02 01:00:00  23.128886  \n...                        ...  \n2023-09-05 19:00:00  62.202290  \n2023-09-05 20:00:00  52.837561  \n2023-09-05 21:00:00  44.106647  \n2023-09-05 22:00:00  36.699240  \n2023-09-05 23:00:00  33.580095  \n\n[32192 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>macd_signal</th>\n      <th>macd_hist</th>\n      <th>rsi</th>\n      <th>mfi</th>\n      <th>roc</th>\n      <th>stoch_d</th>\n    </tr>\n    <tr>\n      <th>date_close</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2020-01-01 21:00:00</th>\n      <td>131.88</td>\n      <td>132.24</td>\n      <td>131.68</td>\n      <td>132.15</td>\n      <td>6486.249190</td>\n      <td>0.235575</td>\n      <td>0.061309</td>\n      <td>64.528279</td>\n      <td>75.703253</td>\n      <td>1.373121</td>\n      <td>68.789809</td>\n    </tr>\n    <tr>\n      <th>2020-01-01 22:00:00</th>\n      <td>132.17</td>\n      <td>132.35</td>\n      <td>131.66</td>\n      <td>131.78</td>\n      <td>7816.579777</td>\n      <td>0.242430</td>\n      <td>0.027101</td>\n      <td>57.417357</td>\n      <td>75.384501</td>\n      <td>1.244622</td>\n      <td>66.135881</td>\n    </tr>\n    <tr>\n      <th>2020-01-01 23:00:00</th>\n      <td>131.79</td>\n      <td>131.79</td>\n      <td>129.94</td>\n      <td>130.30</td>\n      <td>20002.611452</td>\n      <td>0.222974</td>\n      <td>-0.077105</td>\n      <td>38.934904</td>\n      <td>68.772269</td>\n      <td>-0.290787</td>\n      <td>48.613713</td>\n    </tr>\n    <tr>\n      <th>2020-01-02 00:00:00</th>\n      <td>130.31</td>\n      <td>130.84</td>\n      <td>129.72</td>\n      <td>130.69</td>\n      <td>9964.581162</td>\n      <td>0.193149</td>\n      <td>-0.118420</td>\n      <td>44.046228</td>\n      <td>62.935442</td>\n      <td>-0.030597</td>\n      <td>34.161458</td>\n    </tr>\n    <tr>\n      <th>2020-01-02 01:00:00</th>\n      <td>130.68</td>\n      <td>130.74</td>\n      <td>130.24</td>\n      <td>130.64</td>\n      <td>7074.222738</td>\n      <td>0.157382</td>\n      <td>-0.142224</td>\n      <td>43.543018</td>\n      <td>63.200834</td>\n      <td>-0.699301</td>\n      <td>23.128886</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2023-09-05 19:00:00</th>\n      <td>1636.21</td>\n      <td>1637.81</td>\n      <td>1633.44</td>\n      <td>1636.64</td>\n      <td>197.037785</td>\n      <td>0.578337</td>\n      <td>1.253726</td>\n      <td>57.699871</td>\n      <td>69.530462</td>\n      <td>0.915033</td>\n      <td>62.202290</td>\n    </tr>\n    <tr>\n      <th>2023-09-05 20:00:00</th>\n      <td>1636.65</td>\n      <td>1639.21</td>\n      <td>1631.98</td>\n      <td>1632.36</td>\n      <td>239.310545</td>\n      <td>0.789990</td>\n      <td>0.846612</td>\n      <td>51.415045</td>\n      <td>64.067680</td>\n      <td>0.459105</td>\n      <td>52.837561</td>\n    </tr>\n    <tr>\n      <th>2023-09-05 21:00:00</th>\n      <td>1632.36</td>\n      <td>1633.61</td>\n      <td>1626.93</td>\n      <td>1629.93</td>\n      <td>561.978536</td>\n      <td>0.886185</td>\n      <td>0.384782</td>\n      <td>48.204677</td>\n      <td>59.749397</td>\n      <td>0.337345</td>\n      <td>44.106647</td>\n    </tr>\n    <tr>\n      <th>2023-09-05 22:00:00</th>\n      <td>1629.78</td>\n      <td>1633.55</td>\n      <td>1629.73</td>\n      <td>1630.50</td>\n      <td>68.132906</td>\n      <td>0.912046</td>\n      <td>0.103441</td>\n      <td>49.008965</td>\n      <td>58.781891</td>\n      <td>-0.107214</td>\n      <td>36.699240</td>\n    </tr>\n    <tr>\n      <th>2023-09-05 23:00:00</th>\n      <td>1630.90</td>\n      <td>1632.00</td>\n      <td>1629.88</td>\n      <td>1631.88</td>\n      <td>63.297790</td>\n      <td>0.912404</td>\n      <td>0.001433</td>\n      <td>50.993083</td>\n      <td>55.078108</td>\n      <td>-0.101620</td>\n      <td>33.580095</td>\n    </tr>\n  </tbody>\n</table>\n<p>32192 rows √ó 11 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# –°–∫–∞–ª–µ—Ä -1,1 ","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(-1, 1))\n\ndata_train_scale = scaler.fit_transform(data_train)\n\nimport joblib\n!mkdir -p /kaggle/working/SPX/1d/keras2/\n\n# –ü—É—Ç—å, –∫—É–¥–∞ –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω scaler\nscaler_filename = '/kaggle/working/SPX/1d/keras2/scaler_btc1h.save'\n\n# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ scaler\njoblib.dump(scaler, scaler_filename)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T16:38:08.442746Z","iopub.execute_input":"2024-06-02T16:38:08.443532Z","iopub.status.idle":"2024-06-02T16:38:10.333522Z","shell.execute_reply.started":"2024-06-02T16:38:08.443497Z","shell.execute_reply":"2024-06-02T16:38:10.332249Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/SPX/1d/keras2/scaler_btc1h.save']"},"metadata":{}}]},{"cell_type":"markdown","source":"# –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ 9 –∫–ª—é—á–µ–π –∏ 3 –≤—ã—Ö–æ–¥ close","metadata":{}},{"cell_type":"code","source":"data_train_scale","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# –ú–æ–¥–µ–ª—å —Å Attention","metadata":{}},{"cell_type":"code","source":"\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import GlobalAveragePooling1D\nfrom tensorflow.keras.layers import LSTM, Dense, Attention, Input, Concatenate\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\n# –°–Ω–∞—á–∞–ª–∞ —É–±–µ–¥–∏–º—Å—è, —á—Ç–æ –Ω–µ—Ç –Ω—É–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ —Å—Ç–æ–ª–±—Ü–µ volume, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å\n#data = data[data['volume'] != 0]\ndata = data[(data['volume'] != 0) & (data['rsi'] != 0)]\n\n# –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö c –§–ò–ë–ê–ù–ê–ß–ß–ò\n#features = ['open', 'high', 'low', 'close', 'volume', 'macd', 'macd_signal', 'macd_hist', 'rsi', 'pivot', 's1', 's2', 's3', 'r1', 'r2', 'r3']\n# –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n#features = ['open', 'high', 'low', 'close', 'volume', 'macd', 'macd_signal', 'macd_hist', 'rsi', 'pivot', 's1', 's2', 's3', 'r1', 'r2', 'r3', 'obv', 'mfi', 'bollinger_upper', 'bollinger_middle', 'bollinger_lower', 'roc', 'stoch_k', 'stoch_d', 'vwap']\n#features = ['open', 'high', 'low', 'close', 'volume', 'macd', 'macd_signal', 'macd_hist', 'rsi', 'pivot', 's1', 's2', 's3', 'r1', 'r2', 'r3', 'obv', 'mfi', 'roc', 'stoch_k', 'stoch_d', 'vwap']\n# –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n#features = ['open', 'high', 'low', 'close', 'volume', 'macd', 'macd_signal', 'macd_hist', 'rsi'] #–ë–ï–ó –§–ò–ë–û–ù–ê–ß–ß–ò\n#features = ['open', 'high', 'low', 'close', 'volume', 'macd', 'macd_signal', 'macd_hist', 'rsi', 'obv', 'mfi', 'roc', 'vwap']\nfeatures = ['open', 'high', 'low', 'close', 'volume', 'macd_signal', 'macd_hist', 'rsi', 'mfi', 'roc', 'stoch_d']\n\ndef prepare_data(data, look_back=100, forecast_horizon=1, train_size=0.7, val_size=0.15):\n    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é, –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏\n    train_split = int(len(data) * train_size)\n    val_split = int(len(data) * (train_size + val_size))\n    \n    train_data = data[:train_split]\n    val_data = data[train_split:val_split]\n    test_data = data[val_split:]\n\n    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\n    scaler = MinMaxScaler(feature_range=(-1, 1))\n    train_scaled = scaler.fit_transform(train_data[features])\n    val_scaled = scaler.transform(val_data[features])\n    test_scaled = scaler.transform(test_data[features])\n    \n    def create_sequences(scaled_data):\n        X, y = [], []\n        for i in range(len(scaled_data) - look_back - forecast_horizon + 1):\n            X.append(scaled_data[i:(i + look_back)])\n            y.append(scaled_data[i + look_back : i + look_back + forecast_horizon, features.index('close')])\n        return np.array(X), np.array(y)\n    \n    X_train, y_train = create_sequences(train_scaled)\n    X_val, y_val = create_sequences(val_scaled)\n    X_test, y_test = create_sequences(test_scaled)\n    \n    return X_train, y_train, X_val, y_val, X_test, y_test, scaler\n\n# 2. –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –º–µ—Ö–∞–Ω–∏–∑–º–æ–º –≤–Ω–∏–º–∞–Ω–∏—è\ndef create_attention_model(input_shape):\n    inputs = Input(shape=input_shape)\n    lstm_out = LSTM(64, return_sequences=True, activation='tanh')(inputs)\n    attention = Attention()([lstm_out, lstm_out])\n    concat = Concatenate()([lstm_out, attention])\n    \n    # –ò–∑–º–µ–Ω–µ–Ω–∏–µ –∑–¥–µ—Å—å: –¥–æ–±–∞–≤–ª—è–µ–º GlobalAveragePooling1D –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∏–∑–º–µ—Ä–µ–Ω–∏—è\n    pooled = GlobalAveragePooling1D()(concat)\n    \n    dense1 = Dense(32, activation='tanh')(pooled)\n    output = Dense(1, activation='linear')(dense1)\n    \n    model = Model(inputs=inputs, outputs=output)\n    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n    return model\n\ndef train_model(X_train, y_train, X_val, y_val, epochs=100, batch_size=32, patience=10):\n    model = create_attention_model(X_train.shape[1:])\n    \n    callbacks = [\n        EarlyStopping(patience=patience, restore_best_weights=True)\n    ]\n    \n    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, \n                        validation_data=(X_val, y_val), callbacks=callbacks, verbose=1)\n    \n    return model, history\n\ndef evaluate_model(model, X_test, y_test, scaler):\n    predictions = model.predict(X_test)\n    \n    # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∫–∞–ª–µ—Ä–∞\n    feature_range = scaler.feature_range\n    scale = (feature_range[1] - feature_range[0]) / (scaler.data_max_ - scaler.data_min_)\n    min_ = feature_range[0] - scaler.data_min_ * scale\n    \n    # –û–±—Ä–∞—Ç–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ –¥–ª—è 'close'\n    close_index = features.index('close')\n    y_test_inv = (y_test * scale[close_index]) + min_[close_index]\n    predictions_inv = (predictions * scale[close_index]) + min_[close_index]\n    \n    mae = np.mean(np.abs(y_test_inv - predictions_inv))\n    rmse = np.sqrt(np.mean((y_test_inv - predictions_inv)**2))\n    \n    # –û—Ü–µ–Ω–∫–∞ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏—è\n    direction_accuracy = np.mean(np.sign(y_test_inv - X_test[:, -1, close_index]) == \n                                 np.sign(predictions_inv - X_test[:, -1, close_index]))\n    \n    return mae, rmse, direction_accuracy\n\n# –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥\nX_train, y_train, X_val, y_val, X_test, y_test, scaler = prepare_data(data)\n\nprint(\"Shape of X_train:\", X_train.shape)\nprint(\"Shape of y_train:\", y_train.shape)\nprint(\"Shape of X_val:\", X_val.shape)\nprint(\"Shape of y_val:\", y_val.shape)\nprint(\"Shape of X_test:\", X_test.shape)\nprint(\"Shape of y_test:\", y_test.shape)\n\nmodel, history = train_model(X_train, y_train, X_val, y_val)\nmae, rmse, direction_accuracy = evaluate_model(model, X_test, y_test, scaler)\n\nprint(f\"MAE: {mae}\")\nprint(f\"RMSE: {rmse}\")\nprint(f\"Direction Accuracy: {direction_accuracy * 100}%\")\n\n# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 6))\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\npredictions = model.predict(X_test)\n\n# –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∫–∞–ª–µ—Ä–∞\nfeature_range = scaler.feature_range\nscale = (feature_range[1] - feature_range[0]) / (scaler.data_max_ - scaler.data_min_)\nmin_ = feature_range[0] - scaler.data_min_ * scale\n\n# –û–±—Ä–∞—Ç–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ –¥–ª—è 'close'\nclose_index = features.index('close')\npredictions_inv = (predictions * scale[close_index]) + min_[close_index]\ny_test_inv = (y_test * scale[close_index]) + min_[close_index]\n\nplt.figure(figsize=(12, 6))\nplt.plot(y_test_inv[:, -1], label='Actual')  # –ü–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞\nplt.plot(predictions_inv[:, -1], label='Predicted')  # –ü–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞\nplt.title('Bitcoin Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Price')\nplt.legend()\n\nimport joblib\n\n# –ü—É—Ç—å, –∫—É–¥–∞ –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω scaler\nscaler_filename = '/kaggle/working/scaler_eth1hATNN.save'\n\n# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ scaler\njoblib.dump(scaler, scaler_filename)\nmodel.save('/kaggle/working/ETH1H_5Mpar11ENTRY1barsoutyfin100IN100epochATNN.keras')","metadata":{"execution":{"iopub.status.busy":"2024-08-12T09:53:45.394595Z","iopub.execute_input":"2024-08-12T09:53:45.394945Z","iopub.status.idle":"2024-08-12T09:53:58.271868Z","shell.execute_reply.started":"2024-08-12T09:53:45.394917Z","shell.execute_reply":"2024-08-12T09:53:58.270624Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-08-12 09:53:47.522845: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-12 09:53:47.522945: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-12 09:53:47.653178: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Shape of X_train: (28167, 100, 11)\nShape of y_train: (28167, 1)\nShape of X_test: (5958, 100, 11)\nShape of y_test: (5958, 1)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 112\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of X_test:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of y_test:\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 112\u001b[0m model, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m mae, rmse, direction_accuracy \u001b[38;5;241m=\u001b[39m evaluate_model(model, X_test, y_test, scaler)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmae\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mTypeError\u001b[0m: train_model() missing 2 required positional arguments: 'X_val' and 'y_val'"],"ename":"TypeError","evalue":"train_model() missing 2 required positional arguments: 'X_val' and 'y_val'","output_type":"error"}]},{"cell_type":"code","source":"import joblib\n\n# –ü—É—Ç—å, –∫—É–¥–∞ –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω scaler\nscaler_filename = '/kaggle/working/scaler_btc1hATNN.save'\n\n# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ scaler\njoblib.dump(scaler, scaler_filename)\nmodel.save('/kaggle/working/BTC1H_5Mpar11ENTRY1barsoutyfin100IN100epochATNN.keras')","metadata":{"execution":{"iopub.status.busy":"2024-08-04T08:34:05.724293Z","iopub.execute_input":"2024-08-04T08:34:05.725025Z","iopub.status.idle":"2024-08-04T08:34:05.760301Z","shell.execute_reply.started":"2024-08-04T08:34:05.724993Z","shell.execute_reply":"2024-08-04T08:34:05.759273Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö X –∏ Y\nx = []\ny = []\n\n# –¶–∏–∫–ª –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤—Ö–æ–¥–Ω–æ–≥–æ –æ–∫–Ω–∞ –∏ –æ—Ç–≤–µ—Ç–æ–≤\nfor i in range(40, len(data_train_scale)):\n    x.append(data_train_scale[i-40:i])  # 100 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –¥–æ i\n    y.append(data_train_scale[i, 3])     # –ò–Ω–¥–µ–∫—Å 3 - —ç—Ç–æ 'close', –∫–∞–∫ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–ª–æ—Å—å\n\n# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤ –º–∞—Å—Å–∏–≤ NumPy –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏\nx, y = np.array(x), np.array(y)\n\n# –ò–∑–º–µ–Ω—è–µ–º —Ñ–æ—Ä–º—É x –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–æ–≤–æ–≥–æ –∏–∑–º–µ—Ä–µ–Ω–∏—è, —Ç–∞–∫ –∫–∞–∫ LSTM –æ–∂–∏–¥–∞–µ—Ç —Ç—Ä–µ—Ö–º–µ—Ä–Ω—ã–π —Ç–µ–Ω–∑–æ—Ä\n# –¢–µ–ø–µ—Ä—å 'features' —Ä–∞–≤–Ω–æ 9, —Ç–∞–∫ –∫–∞–∫ —É –≤–∞—Å 9 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\nx = np.reshape(x, (x.shape[0], x.shape[1], len(features)))  # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑ 5 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ 9\n\n# –í—ã–≤–æ–¥ —Ñ–æ—Ä–º—ã –º–∞—Å—Å–∏–≤–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\nprint(\"–§–æ—Ä–º–∞ –º–∞—Å—Å–∏–≤–∞ x:\", x.shape)\nprint(\"–§–æ—Ä–º–∞ –º–∞—Å—Å–∏–≤–∞ y:\", y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# –ü–æ–¥–≥–æ—Ç–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥ 16 –≤—Ö–æ–¥–æ–≤ –∏ –≤—ã—Ö–æ–¥ 5 –±–∞—Ä–æ–≤ CLose","metadata":{}},{"cell_type":"code","source":"x = []\ny = []\n\n# –¶–∏–∫–ª –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤—Ö–æ–¥–Ω–æ–≥–æ –æ–∫–Ω–∞ –∏ –æ—Ç–≤–µ—Ç–æ–≤\nlook_back = 100  # –†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ –æ–∫–Ω–∞\nlook_forward = 4  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n\nfor i in range(look_back, len(data_train_scale) - look_forward + 1):\n    x.append(data_train_scale[i-look_back:i])  # 100 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –¥–æ i\n    y.append(data_train_scale[i:i + look_forward, 3])  # –ò–Ω–¥–µ–∫—Å 3 - —ç—Ç–æ 'close', —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è\n\n# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤ –º–∞—Å—Å–∏–≤ NumPy –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏\nx, y = np.array(x), np.array(y)\n\n# –ò–∑–º–µ–Ω—è–µ–º —Ñ–æ—Ä–º—É x –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–æ–≤–æ–≥–æ –∏–∑–º–µ—Ä–µ–Ω–∏—è, —Ç–∞–∫ –∫–∞–∫ LSTM –æ–∂–∏–¥–∞–µ—Ç —Ç—Ä–µ—Ö–º–µ—Ä–Ω—ã–π —Ç–µ–Ω–∑–æ—Ä\n# –û–±–Ω–æ–≤–ª—è–µ–º —á–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –∫–∞–∂–¥–æ–º –≤—Ö–æ–¥–Ω–æ–º –æ–∫–Ω–µ\nx = np.reshape(x, (x.shape[0], x.shape[1], len(features)))  # –¢–µ–ø–µ—Ä—å 'features' —Ä–∞–≤–Ω–æ 16\n\n# –í—ã–≤–æ–¥ —Ñ–æ—Ä–º—ã –º–∞—Å—Å–∏–≤–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\nprint(\"–§–æ—Ä–º–∞ –º–∞—Å—Å–∏–≤–∞ x:\", x.shape)\nprint(\"–§–æ—Ä–º–∞ –º–∞—Å—Å–∏–≤–∞ y:\", y.shape)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-02T16:38:16.603064Z","iopub.execute_input":"2024-06-02T16:38:16.603462Z","iopub.status.idle":"2024-06-02T16:38:16.907476Z","shell.execute_reply.started":"2024-06-02T16:38:16.603427Z","shell.execute_reply":"2024-06-02T16:38:16.906576Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"–§–æ—Ä–º–∞ –º–∞—Å—Å–∏–≤–∞ x: (54736, 100, 11)\n–§–æ—Ä–º–∞ –º–∞—Å—Å–∏–≤–∞ y: (54736, 4)\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\n# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ Residual Block\nclass ResidualBlock(tf.keras.layers.Layer):\n    def __init__(self, model_dim):\n        super(ResidualBlock, self).__init__()\n        self.dense1 = layers.Dense(model_dim, activation='tanh')\n        self.dense2 = layers.Dense(model_dim)\n        \n    def call(self, inputs):\n        x = self.dense1(inputs)\n        x = self.dense2(x)\n        return inputs + x\n\n# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ Positional Encoding Layer\nclass PositionalEncoding(layers.Layer):\n    def __init__(self, max_position, model_dim):\n        super(PositionalEncoding, self).__init__()\n        self.pos_encoding = self.positional_encoding(max_position, model_dim)\n\n    def positional_encoding(self, max_position, model_dim):\n        angle_rads = self.get_angles(np.arange(max_position)[:, np.newaxis],\n                                     np.arange(model_dim)[np.newaxis, :],\n                                     model_dim)\n        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n        pos_encoding = angle_rads[np.newaxis, ...]\n        return tf.cast(pos_encoding, dtype=tf.float32)\n\n    def get_angles(self, pos, i, model_dim):\n        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(model_dim))\n        return pos * angle_rates\n\n    def call(self, inputs):\n        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n\n# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–π LSTM –º–æ–¥–µ–ª–∏\ndef build_improved_lstm_model(input_shape, model_dim):\n    inputs = layers.Input(shape=input_shape)\n    \n    # Positional Encoding\n    x = PositionalEncoding(input_shape[0], model_dim)(inputs)\n    \n    # First LSTM Layer\n    x = layers.LSTM(units=1280, activation='tanh', return_sequences=True)(x)\n    x = layers.Dropout(0.2)(x)\n    x = layers.Dense(model_dim)(x)  # Align dimensions\n    x = ResidualBlock(model_dim)(x)\n    \n    # Second LSTM Layer\n    x = layers.LSTM(units=1280, activation='tanh', return_sequences=True)(x)\n    x = layers.Dropout(0.3)(x)\n    x = layers.Dense(model_dim)(x)  # Align dimensions\n    x = ResidualBlock(model_dim)(x)\n    \n    # Third LSTM Layer\n    x = layers.LSTM(units=1280, activation='tanh', return_sequences=True)(x)\n    x = layers.Dropout(0.4)(x)\n    x = layers.Dense(model_dim)(x)  # Align dimensions\n    x = ResidualBlock(model_dim)(x)\n    \n    # Fourth LSTM Layer\n    x = layers.LSTM(units=1280, activation='tanh')(x)\n    x = layers.Dropout(0.5)(x)\n    x = layers.Dense(model_dim)(x)  # Align dimensions\n    x = ResidualBlock(model_dim)(x)\n    \n    # Output Layer\n    outputs = layers.Dense(units=look_forward)(x)\n    \n    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n    model = models.Model(inputs=inputs, outputs=outputs)\n    return model\n\n# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏\ninput_shape = (x.shape[1], x.shape[2])\nmodel_dim = input_shape[1]  # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –±—É–¥–µ—Ç —Ä–∞–≤–Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n\n# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏\nimproved_lstm_model = build_improved_lstm_model(input_shape, model_dim)\nimproved_lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n\n# –í—ã–≤–æ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏\nimproved_lstm_model.summary()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# –ú–æ–¥–µ–ª—å 9 –≤—Ö–æ–¥–æ–≤ –∏ –ø—Ä–æ–≥–Ω–æ–∑ 5 close –≤–ø–µ—Ä–µ–¥ –∏ –±–∞—Ç—á –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä","metadata":{}},{"cell_type":"code","source":"from keras.layers import Dense, Dropout, LSTM, BatchNormalization\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\n\n# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\nmodel = Sequential()\nmodel.add(LSTM(units=200, activation='tanh', return_sequences=True, input_shape=(x.shape[1], x.shape[2])))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units=300, activation='tanh', return_sequences=True))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(LSTM(units=500, activation='tanh', return_sequences=True))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\n\nmodel.add(LSTM(units=600, activation='tanh'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n# –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π\nmodel.add(Dense(units=look_forward))\n\n# –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º clipnorm –∏ —É–º–µ–Ω—å—à–µ–Ω–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç—å—é –æ–±—É—á–µ–Ω–∏—è\n#optimizer = Adam(learning_rate=0.00001, clipvalue=1.0)\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# –í—ã–≤–æ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏\nmodel.summary()\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# –ú–æ–¥–µ–ª—å —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π —Å–ª–æ–µ–≤","metadata":{}},{"cell_type":"code","source":"from keras.layers import Dense, Dropout, LSTM, GroupNormalization\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\n\n# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\nmodel = Sequential()\n\n# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Å–ª–æ—è –ø–µ—Ä–µ–¥ LSTM\nmodel.add(GroupNormalization(groups=2, input_shape=(x.shape[1], x.shape[2])))\n\n# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ª–æ–µ–≤ LSTM —Å Dropout –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–µ–π tanh\nmodel.add(LSTM(units=200, activation='tanh', return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(GroupNormalization(groups=2))\n\nmodel.add(LSTM(units=300, activation='tanh', return_sequences=True))\nmodel.add(Dropout(0.3))\nmodel.add(GroupNormalization(groups=2))\n\nmodel.add(LSTM(units=500, activation='tanh', return_sequences=True))\nmodel.add(Dropout(0.4))\nmodel.add(GroupNormalization(groups=2))\n\nmodel.add(LSTM(units=600, activation='tanh'))\nmodel.add(Dropout(0.5))\nmodel.add(GroupNormalization(groups=2))\n\n# Dense —Å–ª–æ–π —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –Ω–µ–π—Ä–æ–Ω–æ–≤, —Ä–∞–≤–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n#model.add(Dense(units=len(features), activation='tanh'))\n\n# –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π –±–µ–∑ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏\nmodel.add(Dense(units=look_forward))\n\n# –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏\noptimizer = Adam(learning_rate=0.001)\nmodel.compile(optimizer=optimizer, loss='mean_squared_error')\n\n# –í—ã–≤–æ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏\nmodel.summary()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Dense, Dropout, LSTM, BatchNormalization\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam, RMSprop\n\n# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\nmodel = Sequential()\nmodel.add(LSTM(units=200, activation='tanh', return_sequences=True, input_shape=(x.shape[1], x.shape[2])))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units=300, activation='tanh', return_sequences=True))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(LSTM(units=500, activation='tanh', return_sequences=True))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\n\nmodel.add(LSTM(units=600, activation='tanh'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n# –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π\nmodel.add(Dense(units=look_forward))\n\n# –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º clipnorm –∏ —É–º–µ–Ω—å—à–µ–Ω–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç—å—é –æ–±—É—á–µ–Ω–∏—è\n#optimizer = Adam(learning_rate=0.00001)\n#model.compile(optimizer=optimizer, loss='mean_squared_error')\n# –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RMSprop –∏ Huber Loss\noptimizer = RMSprop(learning_rate=0.001)\nmodel.compile(optimizer=optimizer, loss='huber')\n\n# –í—ã–≤–æ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# –ú–æ–¥–µ–ª—å 16 –≤—Ö–æ–¥–æ–≤ –∏ –ø—Ä–æ–≥–Ω–æ–∑ 5 close –≤–ø–µ—Ä–µ–¥ 182–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤","metadata":{}},{"cell_type":"code","source":"from keras.layers import Dense, Dropout, LSTM\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam, RMSprop\n# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\nmodel = Sequential()\n\n# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ª–æ–µ–≤ LSTM —Å Dropout –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–µ–π tanh\nmodel.add(LSTM(units=200, activation='tanh', return_sequences=True, input_shape=(x.shape[1], x.shape[2])))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units=300, activation='tanh', return_sequences=True))\nmodel.add(Dropout(0.3))\n\nmodel.add(LSTM(units=500, activation='tanh', return_sequences=True))\nmodel.add(Dropout(0.4))\n\nmodel.add(LSTM(units=600, activation='tanh'))\nmodel.add(Dropout(0.5))\n\n# Dense —Å–ª–æ–π —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –Ω–µ–π—Ä–æ–Ω–æ–≤, —Ä–∞–≤–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, —Å –∞–∫—Ç–∏–≤–∞—Ü–∏–µ–π tanh\n#model.add(Dense(units=len(features), activation='tanh'))\nmodel.add(Dense(units=look_forward))  # –ò–∑–º–µ–Ω–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö –µ–¥–∏–Ω–∏—Ü –Ω–∞ 5\noptimizer = Adam(learning_rate=0.001)\n# –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏\nmodel.compile(optimizer=optimizer, loss='mean_squared_error')\n\n# –í—ã–≤–æ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-02T16:38:35.408954Z","iopub.execute_input":"2024-06-02T16:38:35.409905Z","iopub.status.idle":"2024-06-02T16:38:48.401315Z","shell.execute_reply.started":"2024-06-02T16:38:35.409855Z","shell.execute_reply":"2024-06-02T16:38:48.400427Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"2024-06-02 16:38:36.973705: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-02 16:38:36.973820: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-02 16:38:37.081988: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n lstm (LSTM)                 (None, 100, 200)          169600    \n                                                                 \n dropout (Dropout)           (None, 100, 200)          0         \n                                                                 \n lstm_1 (LSTM)               (None, 100, 300)          601200    \n                                                                 \n dropout_1 (Dropout)         (None, 100, 300)          0         \n                                                                 \n lstm_2 (LSTM)               (None, 100, 500)          1602000   \n                                                                 \n dropout_2 (Dropout)         (None, 100, 500)          0         \n                                                                 \n lstm_3 (LSTM)               (None, 600)               2642400   \n                                                                 \n dropout_3 (Dropout)         (None, 600)               0         \n                                                                 \n dense (Dense)               (None, 4)                 2404      \n                                                                 \n=================================================================\nTotal params: 5017604 (19.14 MB)\nTrainable params: 5017604 (19.14 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.layers import Dense, Dropout, LSTM\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam, RMSprop\n# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\nmodel = Sequential()\n\n# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ª–æ–µ–≤ LSTM —Å Dropout –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–µ–π tanh\nmodel.add(LSTM(units=1000, activation='tanh', return_sequences=True, input_shape=(x.shape[1], x.shape[2])))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units=1000, activation='tanh', return_sequences=True))\nmodel.add(Dropout(0.3))\n\nmodel.add(LSTM(units=2500, activation='tanh', return_sequences=True))\nmodel.add(Dropout(0.4))\n\nmodel.add(LSTM(units=3000, activation='tanh'))\nmodel.add(Dropout(0.5))\n\n# Dense —Å–ª–æ–π —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –Ω–µ–π—Ä–æ–Ω–æ–≤, —Ä–∞–≤–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, —Å –∞–∫—Ç–∏–≤–∞—Ü–∏–µ–π tanh\n#model.add(Dense(units=len(features), activation='tanh'))\nmodel.add(Dense(units=look_forward))  # –ò–∑–º–µ–Ω–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö –µ–¥–∏–Ω–∏—Ü –Ω–∞ 5\noptimizer = Adam(learning_rate=0.001)\n# –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏\nmodel.compile(optimizer=optimizer, loss='mean_squared_error')\n\n# –í—ã–≤–æ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Dense, Dropout, LSTM\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam, RMSprop\n# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\nmodel = Sequential()\n\n# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ª–æ–µ–≤ LSTM —Å Dropout –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–µ–π tanh\nmodel.add(LSTM(units=50, activation='tanh', return_sequences=True, input_shape=(x.shape[1], x.shape[2])))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units=60, activation='tanh', return_sequences=True, input_shape=(x.shape[1], x.shape[2])))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units=80, activation='tanh', return_sequences=True))\nmodel.add(Dropout(0.3))\n\nmodel.add(LSTM(units=90, activation='tanh', return_sequences=True, input_shape=(x.shape[1], x.shape[2])))\nmodel.add(Dropout(0.3))\n\nmodel.add(LSTM(units=100, activation='tanh', return_sequences=True, input_shape=(x.shape[1], x.shape[2])))\nmodel.add(Dropout(0.4))\n\nmodel.add(LSTM(units=110, activation='tanh', return_sequences=True))\nmodel.add(Dropout(0.4))\n\nmodel.add(LSTM(units=120, activation='tanh'))\nmodel.add(Dropout(0.5))\n\n# –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π\nmodel.add(Dense(units=look_forward))  # –ò–∑–º–µ–Ω–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö –µ–¥–∏–Ω–∏—Ü –Ω–∞ 5\n\n# –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# –í—ã–≤–æ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# –ú–æ–¥–µ–ª—å –ø–æ–¥ 9 –≤—Ö–æ–¥–æ–≤ tanh","metadata":{}},{"cell_type":"code","source":"from keras.layers import Dense, Dropout, LSTM\nfrom keras.models import Sequential\n\n# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\nmodel = Sequential()\n\n# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ª–æ–µ–≤ LSTM —Å Dropout –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–µ–π tanh\nmodel.add(LSTM(units=10, activation='tanh', return_sequences=True, input_shape=(x.shape[1], x.shape[2])))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units=20, activation='tanh', return_sequences=True))\nmodel.add(Dropout(0.3))\n\nmodel.add(LSTM(units=30, activation='tanh', return_sequences=True))\nmodel.add(Dropout(0.4))\n\nmodel.add(LSTM(units=50, activation='tanh'))\nmodel.add(Dropout(0.5))\n\n# –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π\nmodel.add(Dense(units=1))\n\n# –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# –í—ã–≤–æ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏\nmodel.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Dense, Dropout, LSTM\nfrom keras.models import Sequential\n\n# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\nmodel = Sequential()\n\n# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ª–æ–µ–≤ LSTM —Å Dropout –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–µ–π tanh\nmodel.add(LSTM(units=200, activation='tanh', return_sequences=True, input_shape=(x.shape[1], x.shape[2])))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units=300, activation='tanh', return_sequences=True))\nmodel.add(Dropout(0.3))\n\nmodel.add(LSTM(units=500, activation='tanh', return_sequences=True))\nmodel.add(Dropout(0.4))\n\nmodel.add(LSTM(units=600, activation='tanh'))\nmodel.add(Dropout(0.5))\n\n# –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π\nmodel.add(Dense(units=1))\n\n# –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# –í—ã–≤–æ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# –û–±—É—á–µ–Ω–∏–µ# ","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback\nimport numpy as np\n\nclass RMSECallback(Callback):\n    def on_train_begin(self, logs={}):\n        self.train_rmse = []\n        self.val_rmse = []\n\n    def on_epoch_end(self, epoch, logs={}):\n        train_rmse = np.sqrt(logs.get('loss'))\n        val_rmse = np.sqrt(logs.get('val_loss'))\n        self.train_rmse.append(train_rmse)\n        self.val_rmse.append(val_rmse)\n        print(f' ‚Äî train_rmse: {train_rmse:.4f} ‚Äî val_rmse: {val_rmse:.4f}')\n\n# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∏ —É–º–µ–Ω—å—à–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è\nearly_stopping = EarlyStopping(monitor='val_loss', patience=70, restore_best_weights=True, start_from_epoch=10, verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=15, min_lr=1e-8, verbose=1)\nrmse_callback = RMSECallback()\n\n# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\nbatch_size = 32\nprint(f\"Training with batch size: {batch_size}\")\nhistory = model.fit(\n    x, y,\n    epochs=500,\n    batch_size=batch_size,\n    validation_split=0.1,\n    callbacks=[early_stopping, rmse_callback, reduce_lr],\n    verbose=1\n)\n\n# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='validation loss')\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(rmse_callback.train_rmse, label='train RMSE')\nplt.plot(rmse_callback.val_rmse, label='validation RMSE')\nplt.title('Model RMSE')\nplt.ylabel('RMSE')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-02T16:38:56.128593Z","iopub.execute_input":"2024-06-02T16:38:56.129292Z","iopub.status.idle":"2024-06-02T19:08:41.425317Z","shell.execute_reply.started":"2024-06-02T16:38:56.129249Z","shell.execute_reply":"2024-06-02T19:08:41.424313Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Training with batch size: 32\nEpoch 1/500\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1717346344.095022     157 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"1540/1540 [==============================] - ETA: 0s - loss: 0.0139 ‚Äî train_rmse: 0.1181 ‚Äî val_rmse: 0.0166\n1540/1540 [==============================] - 87s 51ms/step - loss: 0.0139 - val_loss: 2.7520e-04 - lr: 0.0010\nEpoch 2/500\n1540/1540 [==============================] - ETA: 0s - loss: 0.0033 ‚Äî train_rmse: 0.0577 ‚Äî val_rmse: 0.0148\n1540/1540 [==============================] - 78s 51ms/step - loss: 0.0033 - val_loss: 2.1829e-04 - lr: 0.0010\nEpoch 3/500\n1540/1540 [==============================] - ETA: 0s - loss: 0.0029 ‚Äî train_rmse: 0.0543 ‚Äî val_rmse: 0.0409\n1540/1540 [==============================] - 78s 51ms/step - loss: 0.0029 - val_loss: 0.0017 - lr: 0.0010\nEpoch 4/500\n1539/1540 [============================>.] - ETA: 0s - loss: 0.0025 ‚Äî train_rmse: 0.0500 ‚Äî val_rmse: 0.0229\n1540/1540 [==============================] - 78s 50ms/step - loss: 0.0025 - val_loss: 5.2479e-04 - lr: 0.0010\nEpoch 5/500\n1539/1540 [============================>.] - ETA: 0s - loss: 0.0021 ‚Äî train_rmse: 0.0458 ‚Äî val_rmse: 0.0163\n1540/1540 [==============================] - 78s 51ms/step - loss: 0.0021 - val_loss: 2.6689e-04 - lr: 0.0010\nEpoch 6/500\n1540/1540 [==============================] - ETA: 0s - loss: 0.0018 ‚Äî train_rmse: 0.0423 ‚Äî val_rmse: 0.0164\n1540/1540 [==============================] - 78s 51ms/step - loss: 0.0018 - val_loss: 2.6968e-04 - lr: 0.0010\nEpoch 7/500\n1540/1540 [==============================] - ETA: 0s - loss: 0.0016 ‚Äî train_rmse: 0.0401 ‚Äî val_rmse: 0.0142\n1540/1540 [==============================] - 78s 50ms/step - loss: 0.0016 - val_loss: 2.0297e-04 - lr: 0.0010\nEpoch 8/500\n1540/1540 [==============================] - ETA: 0s - loss: 0.0015 ‚Äî train_rmse: 0.0383 ‚Äî val_rmse: 0.0192\n1540/1540 [==============================] - 78s 51ms/step - loss: 0.0015 - val_loss: 3.6983e-04 - lr: 0.0010\nEpoch 9/500\n1540/1540 [==============================] - ETA: 0s - loss: 0.0013 ‚Äî train_rmse: 0.0363 ‚Äî val_rmse: 0.0090\n1540/1540 [==============================] - 78s 51ms/step - loss: 0.0013 - val_loss: 8.1129e-05 - lr: 0.0010\nEpoch 10/500\n1539/1540 [============================>.] - ETA: 0s - loss: 0.0012 ‚Äî train_rmse: 0.0348 ‚Äî val_rmse: 0.0122\n1540/1540 [==============================] - 78s 51ms/step - loss: 0.0012 - val_loss: 1.4912e-04 - lr: 0.0010\nEpoch 11/500\n1539/1540 [============================>.] - ETA: 0s - loss: 0.0012 ‚Äî train_rmse: 0.0342 ‚Äî val_rmse: 0.0081\n1540/1540 [==============================] - 78s 51ms/step - loss: 0.0012 - val_loss: 6.4823e-05 - lr: 0.0010\nEpoch 12/500\n1540/1540 [==============================] - ETA: 0s - loss: 0.0011 ‚Äî train_rmse: 0.0330 ‚Äî val_rmse: 0.0114\n1540/1540 [==============================] - 78s 50ms/step - loss: 0.0011 - val_loss: 1.2967e-04 - lr: 0.0010\nEpoch 13/500\n1540/1540 [==============================] - ETA: 0s - loss: 0.0010 ‚Äî train_rmse: 0.0319 ‚Äî val_rmse: 0.0139\n1540/1540 [==============================] - 78s 51ms/step - loss: 0.0010 - val_loss: 1.9438e-04 - lr: 0.0010\nEpoch 14/500\n1540/1540 [==============================] - ETA: 0s - loss: 9.4382e-04 ‚Äî train_rmse: 0.0307 ‚Äî val_rmse: 0.0128\n1540/1540 [==============================] - 78s 51ms/step - loss: 9.4382e-04 - val_loss: 1.6347e-04 - lr: 0.0010\nEpoch 15/500\n1540/1540 [==============================] - ETA: 0s - loss: 9.4528e-04 ‚Äî train_rmse: 0.0307 ‚Äî val_rmse: 0.0085\n1540/1540 [==============================] - 78s 51ms/step - loss: 9.4528e-04 - val_loss: 7.1771e-05 - lr: 0.0010\nEpoch 16/500\n1539/1540 [============================>.] - ETA: 0s - loss: 8.7908e-04 ‚Äî train_rmse: 0.0296 ‚Äî val_rmse: 0.0075\n1540/1540 [==============================] - 78s 51ms/step - loss: 8.7889e-04 - val_loss: 5.6342e-05 - lr: 0.0010\nEpoch 17/500\n1539/1540 [============================>.] - ETA: 0s - loss: 8.8204e-04 ‚Äî train_rmse: 0.0297 ‚Äî val_rmse: 0.0092\n1540/1540 [==============================] - 78s 51ms/step - loss: 8.8188e-04 - val_loss: 8.4878e-05 - lr: 0.0010\nEpoch 18/500\n1540/1540 [==============================] - ETA: 0s - loss: 8.9003e-04 ‚Äî train_rmse: 0.0298 ‚Äî val_rmse: 0.0073\n1540/1540 [==============================] - 78s 51ms/step - loss: 8.9003e-04 - val_loss: 5.3494e-05 - lr: 0.0010\nEpoch 19/500\n1540/1540 [==============================] - ETA: 0s - loss: 8.3368e-04 ‚Äî train_rmse: 0.0289 ‚Äî val_rmse: 0.0105\n1540/1540 [==============================] - 78s 51ms/step - loss: 8.3368e-04 - val_loss: 1.1115e-04 - lr: 0.0010\nEpoch 20/500\n1540/1540 [==============================] - ETA: 0s - loss: 8.2284e-04 ‚Äî train_rmse: 0.0287 ‚Äî val_rmse: 0.0122\n1540/1540 [==============================] - 78s 50ms/step - loss: 8.2284e-04 - val_loss: 1.4981e-04 - lr: 0.0010\nEpoch 21/500\n1540/1540 [==============================] - ETA: 0s - loss: 8.4944e-04 ‚Äî train_rmse: 0.0291 ‚Äî val_rmse: 0.0094\n1540/1540 [==============================] - 78s 51ms/step - loss: 8.4944e-04 - val_loss: 8.8799e-05 - lr: 0.0010\nEpoch 22/500\n1540/1540 [==============================] - ETA: 0s - loss: 7.9620e-04 ‚Äî train_rmse: 0.0282 ‚Äî val_rmse: 0.0090\n1540/1540 [==============================] - 78s 51ms/step - loss: 7.9620e-04 - val_loss: 8.1150e-05 - lr: 0.0010\nEpoch 23/500\n1540/1540 [==============================] - ETA: 0s - loss: 8.0094e-04 ‚Äî train_rmse: 0.0283 ‚Äî val_rmse: 0.0085\n1540/1540 [==============================] - 78s 51ms/step - loss: 8.0094e-04 - val_loss: 7.2014e-05 - lr: 0.0010\nEpoch 24/500\n1540/1540 [==============================] - ETA: 0s - loss: 7.6736e-04 ‚Äî train_rmse: 0.0277 ‚Äî val_rmse: 0.0098\n\nEpoch 24: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n1540/1540 [==============================] - 78s 50ms/step - loss: 7.6736e-04 - val_loss: 9.6204e-05 - lr: 0.0010\nEpoch 25/500\n1540/1540 [==============================] - ETA: 0s - loss: 6.1965e-04 ‚Äî train_rmse: 0.0249 ‚Äî val_rmse: 0.0088\n1540/1540 [==============================] - 78s 51ms/step - loss: 6.1965e-04 - val_loss: 7.6834e-05 - lr: 1.0000e-04\nEpoch 26/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.8442e-04 ‚Äî train_rmse: 0.0242 ‚Äî val_rmse: 0.0077\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.8442e-04 - val_loss: 5.9903e-05 - lr: 1.0000e-04\nEpoch 27/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.7649e-04 ‚Äî train_rmse: 0.0240 ‚Äî val_rmse: 0.0070\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.7649e-04 - val_loss: 4.9648e-05 - lr: 1.0000e-04\nEpoch 28/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.6421e-04 ‚Äî train_rmse: 0.0238 ‚Äî val_rmse: 0.0075\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.6421e-04 - val_loss: 5.6005e-05 - lr: 1.0000e-04\nEpoch 29/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.5972e-04 ‚Äî train_rmse: 0.0237 ‚Äî val_rmse: 0.0087\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.5972e-04 - val_loss: 7.6179e-05 - lr: 1.0000e-04\nEpoch 30/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.6738e-04 ‚Äî train_rmse: 0.0238 ‚Äî val_rmse: 0.0088\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.6738e-04 - val_loss: 7.8069e-05 - lr: 1.0000e-04\nEpoch 31/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.6749e-04 ‚Äî train_rmse: 0.0238 ‚Äî val_rmse: 0.0109\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.6749e-04 - val_loss: 1.1868e-04 - lr: 1.0000e-04\nEpoch 32/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.5100e-04 ‚Äî train_rmse: 0.0235 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.5100e-04 - val_loss: 4.7437e-05 - lr: 1.0000e-04\nEpoch 33/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.5706e-04 ‚Äî train_rmse: 0.0236 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.5706e-04 - val_loss: 4.8119e-05 - lr: 1.0000e-04\nEpoch 34/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.6079e-04 ‚Äî train_rmse: 0.0237 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.6079e-04 - val_loss: 4.8256e-05 - lr: 1.0000e-04\nEpoch 35/500\n1539/1540 [============================>.] - ETA: 0s - loss: 5.4388e-04 ‚Äî train_rmse: 0.0233 ‚Äî val_rmse: 0.0079\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.4411e-04 - val_loss: 6.2271e-05 - lr: 1.0000e-04\nEpoch 36/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.4975e-04 ‚Äî train_rmse: 0.0234 ‚Äî val_rmse: 0.0080\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.4975e-04 - val_loss: 6.3757e-05 - lr: 1.0000e-04\nEpoch 37/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.6178e-04 ‚Äî train_rmse: 0.0237 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.6178e-04 - val_loss: 4.8047e-05 - lr: 1.0000e-04\nEpoch 38/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.5137e-04 ‚Äî train_rmse: 0.0235 ‚Äî val_rmse: 0.0068\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.5137e-04 - val_loss: 4.5698e-05 - lr: 1.0000e-04\nEpoch 39/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.4963e-04 ‚Äî train_rmse: 0.0234 ‚Äî val_rmse: 0.0115\n\nEpoch 39: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.4963e-04 - val_loss: 1.3143e-04 - lr: 1.0000e-04\nEpoch 40/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3883e-04 ‚Äî train_rmse: 0.0232 ‚Äî val_rmse: 0.0071\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.3883e-04 - val_loss: 5.0953e-05 - lr: 1.0000e-05\nEpoch 41/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3620e-04 ‚Äî train_rmse: 0.0232 ‚Äî val_rmse: 0.0068\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.3620e-04 - val_loss: 4.5995e-05 - lr: 1.0000e-05\nEpoch 42/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3519e-04 ‚Äî train_rmse: 0.0231 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.3519e-04 - val_loss: 4.7923e-05 - lr: 1.0000e-05\nEpoch 43/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3180e-04 ‚Äî train_rmse: 0.0231 ‚Äî val_rmse: 0.0068\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.3180e-04 - val_loss: 4.6344e-05 - lr: 1.0000e-05\nEpoch 44/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3522e-04 ‚Äî train_rmse: 0.0231 ‚Äî val_rmse: 0.0068\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.3522e-04 - val_loss: 4.5925e-05 - lr: 1.0000e-05\nEpoch 45/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.4011e-04 ‚Äî train_rmse: 0.0232 ‚Äî val_rmse: 0.0067\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.4011e-04 - val_loss: 4.5427e-05 - lr: 1.0000e-05\nEpoch 46/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.4360e-04 ‚Äî train_rmse: 0.0233 ‚Äî val_rmse: 0.0071\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.4360e-04 - val_loss: 5.0609e-05 - lr: 1.0000e-05\nEpoch 47/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3116e-04 ‚Äî train_rmse: 0.0230 ‚Äî val_rmse: 0.0070\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.3116e-04 - val_loss: 4.8887e-05 - lr: 1.0000e-05\nEpoch 48/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.4413e-04 ‚Äî train_rmse: 0.0233 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 77s 50ms/step - loss: 5.4413e-04 - val_loss: 4.7237e-05 - lr: 1.0000e-05\nEpoch 49/500\n1539/1540 [============================>.] - ETA: 0s - loss: 5.3337e-04 ‚Äî train_rmse: 0.0231 ‚Äî val_rmse: 0.0068\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.3330e-04 - val_loss: 4.6188e-05 - lr: 1.0000e-05\nEpoch 50/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3205e-04 ‚Äî train_rmse: 0.0231 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.3205e-04 - val_loss: 4.8245e-05 - lr: 1.0000e-05\nEpoch 51/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2978e-04 ‚Äî train_rmse: 0.0230 ‚Äî val_rmse: 0.0068\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.2978e-04 - val_loss: 4.5638e-05 - lr: 1.0000e-05\nEpoch 52/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2236e-04 ‚Äî train_rmse: 0.0229 ‚Äî val_rmse: 0.0068\n1540/1540 [==============================] - 77s 50ms/step - loss: 5.2236e-04 - val_loss: 4.6488e-05 - lr: 1.0000e-05\nEpoch 53/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.4116e-04 ‚Äî train_rmse: 0.0233 ‚Äî val_rmse: 0.0070\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.4116e-04 - val_loss: 4.9083e-05 - lr: 1.0000e-05\nEpoch 54/500\n1539/1540 [============================>.] - ETA: 0s - loss: 5.2897e-04 ‚Äî train_rmse: 0.0230 ‚Äî val_rmse: 0.0070\n\nEpoch 54: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.2926e-04 - val_loss: 4.8697e-05 - lr: 1.0000e-05\nEpoch 55/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3196e-04 ‚Äî train_rmse: 0.0231 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.3196e-04 - val_loss: 4.7209e-05 - lr: 1.0000e-06\nEpoch 56/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3242e-04 ‚Äî train_rmse: 0.0231 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 77s 50ms/step - loss: 5.3242e-04 - val_loss: 4.7569e-05 - lr: 1.0000e-06\nEpoch 57/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3133e-04 ‚Äî train_rmse: 0.0231 ‚Äî val_rmse: 0.0068\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.3133e-04 - val_loss: 4.6737e-05 - lr: 1.0000e-06\nEpoch 58/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2310e-04 ‚Äî train_rmse: 0.0229 ‚Äî val_rmse: 0.0070\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.2310e-04 - val_loss: 4.8769e-05 - lr: 1.0000e-06\nEpoch 59/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2905e-04 ‚Äî train_rmse: 0.0230 ‚Äî val_rmse: 0.0068\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.2905e-04 - val_loss: 4.6820e-05 - lr: 1.0000e-06\nEpoch 60/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3045e-04 ‚Äî train_rmse: 0.0230 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.3045e-04 - val_loss: 4.7303e-05 - lr: 1.0000e-06\nEpoch 61/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2635e-04 ‚Äî train_rmse: 0.0229 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.2635e-04 - val_loss: 4.8121e-05 - lr: 1.0000e-06\nEpoch 62/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3372e-04 ‚Äî train_rmse: 0.0231 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.3372e-04 - val_loss: 4.8043e-05 - lr: 1.0000e-06\nEpoch 63/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3047e-04 ‚Äî train_rmse: 0.0230 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.3047e-04 - val_loss: 4.7203e-05 - lr: 1.0000e-06\nEpoch 64/500\n1539/1540 [============================>.] - ETA: 0s - loss: 5.3636e-04 ‚Äî train_rmse: 0.0232 ‚Äî val_rmse: 0.0068\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.3637e-04 - val_loss: 4.6698e-05 - lr: 1.0000e-06\nEpoch 65/500\n1539/1540 [============================>.] - ETA: 0s - loss: 5.2350e-04 ‚Äî train_rmse: 0.0229 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.2347e-04 - val_loss: 4.7160e-05 - lr: 1.0000e-06\nEpoch 66/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2648e-04 ‚Äî train_rmse: 0.0229 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.2648e-04 - val_loss: 4.7238e-05 - lr: 1.0000e-06\nEpoch 67/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2231e-04 ‚Äî train_rmse: 0.0229 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.2231e-04 - val_loss: 4.7399e-05 - lr: 1.0000e-06\nEpoch 68/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2253e-04 ‚Äî train_rmse: 0.0229 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.2253e-04 - val_loss: 4.7707e-05 - lr: 1.0000e-06\nEpoch 69/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2702e-04 ‚Äî train_rmse: 0.0230 ‚Äî val_rmse: 0.0068\n\nEpoch 69: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.2702e-04 - val_loss: 4.6739e-05 - lr: 1.0000e-06\nEpoch 70/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3398e-04 ‚Äî train_rmse: 0.0231 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.3398e-04 - val_loss: 4.7068e-05 - lr: 1.0000e-07\nEpoch 71/500\n1539/1540 [============================>.] - ETA: 0s - loss: 5.2424e-04 ‚Äî train_rmse: 0.0229 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.2431e-04 - val_loss: 4.7057e-05 - lr: 1.0000e-07\nEpoch 72/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3221e-04 ‚Äî train_rmse: 0.0231 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.3221e-04 - val_loss: 4.7180e-05 - lr: 1.0000e-07\nEpoch 73/500\n1539/1540 [============================>.] - ETA: 0s - loss: 5.2642e-04 ‚Äî train_rmse: 0.0229 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.2634e-04 - val_loss: 4.6951e-05 - lr: 1.0000e-07\nEpoch 74/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.1937e-04 ‚Äî train_rmse: 0.0228 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.1937e-04 - val_loss: 4.6962e-05 - lr: 1.0000e-07\nEpoch 75/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3705e-04 ‚Äî train_rmse: 0.0232 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.3705e-04 - val_loss: 4.6997e-05 - lr: 1.0000e-07\nEpoch 76/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3692e-04 ‚Äî train_rmse: 0.0232 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 77s 50ms/step - loss: 5.3692e-04 - val_loss: 4.7110e-05 - lr: 1.0000e-07\nEpoch 77/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2702e-04 ‚Äî train_rmse: 0.0230 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.2702e-04 - val_loss: 4.7052e-05 - lr: 1.0000e-07\nEpoch 78/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2869e-04 ‚Äî train_rmse: 0.0230 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.2869e-04 - val_loss: 4.7053e-05 - lr: 1.0000e-07\nEpoch 79/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3462e-04 ‚Äî train_rmse: 0.0231 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.3462e-04 - val_loss: 4.7125e-05 - lr: 1.0000e-07\nEpoch 80/500\n1539/1540 [============================>.] - ETA: 0s - loss: 5.2115e-04 ‚Äî train_rmse: 0.0228 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 77s 50ms/step - loss: 5.2116e-04 - val_loss: 4.6941e-05 - lr: 1.0000e-07\nEpoch 81/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3047e-04 ‚Äî train_rmse: 0.0230 ‚Äî val_rmse: 0.0068\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.3047e-04 - val_loss: 4.6677e-05 - lr: 1.0000e-07\nEpoch 82/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2449e-04 ‚Äî train_rmse: 0.0229 ‚Äî val_rmse: 0.0068\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.2449e-04 - val_loss: 4.6739e-05 - lr: 1.0000e-07\nEpoch 83/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3700e-04 ‚Äî train_rmse: 0.0232 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.3700e-04 - val_loss: 4.6953e-05 - lr: 1.0000e-07\nEpoch 84/500\n1539/1540 [============================>.] - ETA: 0s - loss: 5.1972e-04 ‚Äî train_rmse: 0.0228 ‚Äî val_rmse: 0.0069\n\nEpoch 84: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n1540/1540 [==============================] - 77s 50ms/step - loss: 5.1968e-04 - val_loss: 4.7067e-05 - lr: 1.0000e-07\nEpoch 85/500\n1539/1540 [============================>.] - ETA: 0s - loss: 5.2263e-04 ‚Äî train_rmse: 0.0229 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.2275e-04 - val_loss: 4.7048e-05 - lr: 1.0000e-08\nEpoch 86/500\n1539/1540 [============================>.] - ETA: 0s - loss: 5.3198e-04 ‚Äî train_rmse: 0.0231 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.3192e-04 - val_loss: 4.7031e-05 - lr: 1.0000e-08\nEpoch 87/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3355e-04 ‚Äî train_rmse: 0.0231 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.3355e-04 - val_loss: 4.7027e-05 - lr: 1.0000e-08\nEpoch 88/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3879e-04 ‚Äî train_rmse: 0.0232 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.3879e-04 - val_loss: 4.7017e-05 - lr: 1.0000e-08\nEpoch 89/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2385e-04 ‚Äî train_rmse: 0.0229 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 79s 51ms/step - loss: 5.2385e-04 - val_loss: 4.6997e-05 - lr: 1.0000e-08\nEpoch 90/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3416e-04 ‚Äî train_rmse: 0.0231 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 79s 51ms/step - loss: 5.3416e-04 - val_loss: 4.7029e-05 - lr: 1.0000e-08\nEpoch 91/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2835e-04 ‚Äî train_rmse: 0.0230 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.2835e-04 - val_loss: 4.6992e-05 - lr: 1.0000e-08\nEpoch 92/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2730e-04 ‚Äî train_rmse: 0.0230 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 50ms/step - loss: 5.2730e-04 - val_loss: 4.6985e-05 - lr: 1.0000e-08\nEpoch 93/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2203e-04 ‚Äî train_rmse: 0.0228 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.2203e-04 - val_loss: 4.6971e-05 - lr: 1.0000e-08\nEpoch 94/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.1635e-04 ‚Äî train_rmse: 0.0227 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 79s 51ms/step - loss: 5.1635e-04 - val_loss: 4.6971e-05 - lr: 1.0000e-08\nEpoch 95/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3623e-04 ‚Äî train_rmse: 0.0232 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 79s 51ms/step - loss: 5.3623e-04 - val_loss: 4.6985e-05 - lr: 1.0000e-08\nEpoch 96/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2677e-04 ‚Äî train_rmse: 0.0230 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 78s 51ms/step - loss: 5.2677e-04 - val_loss: 4.6988e-05 - lr: 1.0000e-08\nEpoch 97/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3073e-04 ‚Äî train_rmse: 0.0230 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 79s 51ms/step - loss: 5.3073e-04 - val_loss: 4.7003e-05 - lr: 1.0000e-08\nEpoch 98/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2469e-04 ‚Äî train_rmse: 0.0229 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 79s 51ms/step - loss: 5.2469e-04 - val_loss: 4.6998e-05 - lr: 1.0000e-08\nEpoch 99/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.1970e-04 ‚Äî train_rmse: 0.0228 ‚Äî val_rmse: 0.0069\n\nEpoch 99: ReduceLROnPlateau reducing learning rate to 1e-08.\n1540/1540 [==============================] - 79s 51ms/step - loss: 5.1970e-04 - val_loss: 4.6986e-05 - lr: 1.0000e-08\nEpoch 100/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2564e-04 ‚Äî train_rmse: 0.0229 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 79s 51ms/step - loss: 5.2564e-04 - val_loss: 4.6971e-05 - lr: 1.0000e-08\nEpoch 101/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2956e-04 ‚Äî train_rmse: 0.0230 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 79s 51ms/step - loss: 5.2956e-04 - val_loss: 4.6976e-05 - lr: 1.0000e-08\nEpoch 102/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2366e-04 ‚Äî train_rmse: 0.0229 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 79s 51ms/step - loss: 5.2366e-04 - val_loss: 4.6970e-05 - lr: 1.0000e-08\nEpoch 103/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2400e-04 ‚Äî train_rmse: 0.0229 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 79s 51ms/step - loss: 5.2400e-04 - val_loss: 4.6972e-05 - lr: 1.0000e-08\nEpoch 104/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2736e-04 ‚Äî train_rmse: 0.0230 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 79s 51ms/step - loss: 5.2736e-04 - val_loss: 4.6963e-05 - lr: 1.0000e-08\nEpoch 105/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3240e-04 ‚Äî train_rmse: 0.0231 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 79s 51ms/step - loss: 5.3240e-04 - val_loss: 4.6963e-05 - lr: 1.0000e-08\nEpoch 106/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2414e-04 ‚Äî train_rmse: 0.0229 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 79s 51ms/step - loss: 5.2414e-04 - val_loss: 4.6950e-05 - lr: 1.0000e-08\nEpoch 107/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2218e-04 ‚Äî train_rmse: 0.0229 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 79s 51ms/step - loss: 5.2218e-04 - val_loss: 4.6954e-05 - lr: 1.0000e-08\nEpoch 108/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3597e-04 ‚Äî train_rmse: 0.0232 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 79s 51ms/step - loss: 5.3597e-04 - val_loss: 4.6975e-05 - lr: 1.0000e-08\nEpoch 109/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3201e-04 ‚Äî train_rmse: 0.0231 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 79s 51ms/step - loss: 5.3201e-04 - val_loss: 4.6969e-05 - lr: 1.0000e-08\nEpoch 110/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2817e-04 ‚Äî train_rmse: 0.0230 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 79s 51ms/step - loss: 5.2817e-04 - val_loss: 4.6978e-05 - lr: 1.0000e-08\nEpoch 111/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2415e-04 ‚Äî train_rmse: 0.0229 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 79s 51ms/step - loss: 5.2415e-04 - val_loss: 4.6982e-05 - lr: 1.0000e-08\nEpoch 112/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3223e-04 ‚Äî train_rmse: 0.0231 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 79s 51ms/step - loss: 5.3223e-04 - val_loss: 4.6975e-05 - lr: 1.0000e-08\nEpoch 113/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2361e-04 ‚Äî train_rmse: 0.0229 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 79s 51ms/step - loss: 5.2361e-04 - val_loss: 4.6993e-05 - lr: 1.0000e-08\nEpoch 114/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.3408e-04 ‚Äî train_rmse: 0.0231 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 79s 51ms/step - loss: 5.3408e-04 - val_loss: 4.7024e-05 - lr: 1.0000e-08\nEpoch 115/500\n1540/1540 [==============================] - ETA: 0s - loss: 5.2574e-04Restoring model weights from the end of the best epoch: 45.\n ‚Äî train_rmse: 0.0229 ‚Äî val_rmse: 0.0069\n1540/1540 [==============================] - 79s 51ms/step - loss: 5.2574e-04 - val_loss: 4.7010e-05 - lr: 1.0000e-08\nEpoch 115: early stopping\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–¥–≥—Ä–∞—Ñ–∏–∫–æ–≤\nfig = make_subplots(rows=1, cols=2, subplot_titles=('Model Loss', 'Model RMSE'))\n\n# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Ç–µ—Ä—å –Ω–∞ –ø–µ—Ä–≤—ã–π –ø–æ–¥–≥—Ä–∞—Ñ–∏–∫\nfig.add_trace(go.Scatter(x=list(range(len(history.history['loss']))), y=history.history['loss'], mode='lines', name='Train Loss'), row=1, col=1)\nfig.add_trace(go.Scatter(x=list(range(len(history.history['val_loss']))), y=history.history['val_loss'], mode='lines', name='Validation Loss'), row=1, col=1)\n\n# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö RMSE –Ω–∞ –≤—Ç–æ—Ä–æ–π –ø–æ–¥–≥—Ä–∞—Ñ–∏–∫\nfig.add_trace(go.Scatter(x=list(range(len(rmse_callback.train_rmse))), y=rmse_callback.train_rmse, mode='lines', name='Train RMSE'), row=1, col=2)\nfig.add_trace(go.Scatter(x=list(range(len(rmse_callback.val_rmse))), y=rmse_callback.val_rmse, mode='lines', name='Validation RMSE'), row=1, col=2)\n\n# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—Å–µ–π –∏ –º–∞–∫–µ—Ç–∞\nfig.update_xaxes(title_text='Epoch', row=1, col=1)\nfig.update_yaxes(title_text='Loss', row=1, col=1)\nfig.update_xaxes(title_text='Epoch', row=1, col=2)\nfig.update_yaxes(title_text='RMSE', row=1, col=2)\n\n# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–∞–∫–µ—Ç–∞ –¥–ª—è –æ–±—â–µ–≥–æ –≤–∏–¥–∞\nfig.update_layout(height=400, width=1200, title_text=\"Training and Validation Loss and RMSE\", showlegend=True)\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-02T19:15:58.262556Z","iopub.execute_input":"2024-06-02T19:15:58.263462Z","iopub.status.idle":"2024-06-02T19:15:58.860189Z","shell.execute_reply.started":"2024-06-02T19:15:58.263421Z","shell.execute_reply":"2024-06-02T19:15:58.859388Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"d1d5823c-35c9-464a-b13a-0b24510ef0bf\" class=\"plotly-graph-div\" style=\"height:400px; width:1200px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d1d5823c-35c9-464a-b13a-0b24510ef0bf\")) {                    Plotly.newPlot(                        \"d1d5823c-35c9-464a-b13a-0b24510ef0bf\",                        [{\"mode\":\"lines\",\"name\":\"Train Loss\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114],\"y\":[0.01394138764590025,0.003327318700030446,0.002946295542642474,0.002497516805306077,0.002095248084515333,0.0017873580800369382,0.001605743425898254,0.001465204288251698,0.0013158301590010524,0.0012084466870874166,0.0011673967819660902,0.0010861499467864633,0.0010198476957157254,0.0009438182460144162,0.0009452764643356204,0.0008788919658400118,0.000881875108461827,0.0008900268003344536,0.00083368388004601,0.0008228400838561356,0.0008494365611113608,0.0007962006493471563,0.000800935726147145,0.0007673649815842509,0.000619647849816829,0.0005844185943715274,0.0005764894303865731,0.0005642107571475208,0.0005597230046987534,0.0005673790001310408,0.0005674936110153794,0.0005509962793439627,0.000557059480343014,0.0005607896600849926,0.0005441110697574914,0.0005497537786141038,0.0005617768038064241,0.0005513672949746251,0.0005496296216733754,0.0005388293066062033,0.0005361962248571217,0.0005351870786398649,0.000531798810698092,0.0005352229345589876,0.000540108943823725,0.0005436037899926305,0.000531157711520791,0.0005441284156404436,0.0005333009175956249,0.0005320460186339915,0.0005297809839248657,0.0005223551415838301,0.0005411625606939197,0.0005292595596984029,0.0005319619667716324,0.0005324237863533199,0.0005313287256285548,0.0005231004324741662,0.0005290517001412809,0.0005304539226926863,0.0005263467319309711,0.0005337228067219257,0.0005304678925313056,0.000536370265763253,0.0005234728450886905,0.00052647601114586,0.0005223134648986161,0.0005225349450483918,0.0005270150140859187,0.0005339771159924567,0.0005243085324764252,0.0005322076613083482,0.0005263361381366849,0.0005193655961193144,0.0005370479193516076,0.0005369154969230294,0.0005270161782391369,0.0005286911618895829,0.0005346192046999931,0.0005211607203818858,0.0005304664955474436,0.0005244918866083026,0.0005369953578338027,0.000519684748724103,0.0005227526417002082,0.0005319163901731372,0.0005335491732694209,0.0005387915298342705,0.0005238497979007661,0.0005341603537090123,0.0005283512291498482,0.0005272951093502343,0.0005220252205617726,0.0005163506721146405,0.0005362300435081124,0.0005267697852104902,0.0005307286628521979,0.0005246885702945292,0.0005196983111090958,0.0005256352014839649,0.0005295629380270839,0.0005236600991338491,0.0005240048631094396,0.0005273615824989974,0.0005323985824361444,0.0005241400212980807,0.000522178306709975,0.0005359678179956973,0.000532009347807616,0.0005281722988002002,0.0005241520120762289,0.0005322283250279725,0.0005236116703599691,0.0005340750212781131,0.0005257438751868904],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Validation Loss\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114],\"y\":[0.0002751964202616364,0.00021829344041179866,0.0016735709505155683,0.0005247944500297308,0.00026689283549785614,0.00026967955636791885,0.0002029707538895309,0.0003698277287185192,0.00008112924115266651,0.00014912415645085275,0.00006482344178948551,0.00012967258226126432,0.00019438074377831072,0.00016346873599104583,0.00007177113729994744,0.000056341945310123265,0.00008487836748827249,0.0000534937898919452,0.00011115139204775915,0.000149811792653054,0.00008879893721314147,0.00008114989759633318,0.00007201375410659239,0.0000962042176979594,0.00007683377043576911,0.00005990345380268991,0.00004964763138559647,0.000056005053920671344,0.00007617854134878144,0.00007806866051396355,0.00011867661669384688,0.000047437282773898914,0.00004811889448319562,0.00004825554060516879,0.0000622713632765226,0.00006375726661644876,0.00004804743730346672,0.00004569758311845362,0.00013142947864253074,0.00005095282904221676,0.000045994569518370554,0.00004792318941326812,0.000046344255679287016,0.000045925255108159035,0.00004542698661680333,0.00005060877447249368,0.000048887388402363285,0.00004723667734651826,0.00004618798629962839,0.00004824460847885348,0.000045637672883458436,0.00004648777758120559,0.00004908344635623507,0.00004869711847277358,0.00004720946526504122,0.00004756925773108378,0.000046736502554267645,0.00004876928869634867,0.00004682018334278837,0.000047303459723480046,0.00004812131737708114,0.00004804259515367448,0.000047203437134157866,0.0000466978017357178,0.0000471599523734767,0.00004723819438368082,0.00004739923315355554,0.00004770707892021164,0.00004673927469411865,0.000047067791456356645,0.00004705657556769438,0.0000471801649837289,0.00004695109964814037,0.00004696236283052713,0.00004699727287515998,0.000047109620936680585,0.00004705156243289821,0.00004705290848505683,0.000047124620323302224,0.00004694063318311237,0.00004667701796279289,0.0000467394020233769,0.00004695262759923935,0.00004706728577730246,0.000047047789848875254,0.000047031215217430145,0.00004702687147073448,0.00004701681245933287,0.000046997276513138786,0.00004702946898760274,0.00004699188866652548,0.00004698520206147805,0.000046970795665401965,0.000046970682888058946,0.000046984641812741756,0.00004698770499089733,0.0000470029772259295,0.00004699792043538764,0.00004698603515862487,0.00004697116673924029,0.00004697572148870677,0.00004696950418292545,0.00004697167605627328,0.00004696272299042903,0.000046962552005425096,0.00004694963718065992,0.00004695422467193566,0.00004697511394624598,0.000046968856622697785,0.00004697771146311425,0.00004698221164289862,0.000046974735596450046,0.000046992838178994134,0.00004702357909991406,0.00004700982026406564],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Train RMSE\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114],\"y\":[0.11807365347909012,0.05768291514851209,0.05427978944913543,0.04997516188374058,0.04577387993731068,0.04227715789923606,0.040071728511486174,0.03827798699320143,0.036274373309556324,0.03476271978840863,0.034167188675190856,0.03295678908489817,0.03193505434026574,0.030721625054909062,0.030745348661799565,0.029646112153872924,0.029696382076977442,0.029833316951597147,0.028873584468264588,0.02868518927697943,0.029145094975164532,0.0282170276490483,0.02830080787092738,0.027701353425135224,0.0248927268457441,0.024174751174966154,0.024010194301308206,0.02375312099803983,0.02365846581456104,0.02381971872485149,0.023822124401811428,0.023473309935839102,0.023602107540281525,0.02368099786928314,0.0233261884961408,0.023446828753887032,0.02370183123318585,0.02348121153123546,0.023444180976809052,0.023212697098919877,0.02315591122925465,0.023134110716426185,0.02306076344569043,0.023134885661247336,0.02324024405688815,0.023315312350312412,0.023046859038072652,0.02332656030452076,0.02309330893561217,0.023066122748177497,0.023016971649738496,0.022855090058536854,0.023262900951814235,0.023005641910157665,0.023064300699818158,0.023074310094850503,0.023050568878631928,0.022871388949387533,0.023001123888655547,0.023031585327386528,0.02294224775236662,0.02310244157490558,0.02303188860105279,0.02315966894761782,0.022879528952508846,0.022945065071728603,0.022854178280975582,0.022859023274155697,0.022956807576096434,0.02310794486734934,0.022897784444710478,0.023069626379903688,0.02294201687159795,0.022789594031472224,0.02317429436577536,0.02317143709231323,0.022956832931376597,0.02299328514783355,0.023121833938941634,0.022828944793439002,0.023031858273865866,0.02290178784742149,0.02317316029016765,0.022796595112518515,0.022863784500825934,0.023063312645262762,0.023098683366577864,0.023211883375423684,0.022887765244793256,0.023111909347974958,0.022985891958978842,0.022962907249523833,0.02284787124792532,0.022723350811767188,0.0231566414557058,0.022951465861911526,0.023037548976664116,0.022906081513312773,0.02279689257572391,0.022926735517381554,0.023012234529203892,0.02288362076101265,0.02289115250723387,0.02296435460662889,0.023073763941675065,0.022894104509634805,0.022851221120762343,0.023150978769712897,0.02306532782788088,0.022981999451749193,0.022894366382938597,0.02307007423108934,0.022882562582892004,0.023110063203680625,0.02292910541619298],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Validation RMSE\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114],\"y\":[0.016589045188365615,0.014774756864727035,0.04090930151586028,0.022908392567566386,0.016336855128752784,0.016421923041103282,0.014246780474532865,0.019230905561582877,0.009007177202246357,0.012211640203136217,0.008051300627195926,0.011387386981272936,0.013942049482709159,0.012785489274605249,0.008471784776536019,0.007506127184515545,0.009212945646657885,0.007313944892596963,0.010542836053347274,0.01223976276947613,0.009423318800355927,0.009008323795042737,0.008486091804039855,0.009808374875480617,0.008765487461389077,0.007739732153162014,0.007046107534348058,0.007483652445208245,0.00872803192872147,0.00883564714743428,0.010893879781503323,0.0068874728873440155,0.006936778393692249,0.00694662080476319,0.007891220645535303,0.007984814751542377,0.006931625877344126,0.006759998751364797,0.011464269651509892,0.00713812503688586,0.006781929630891975,0.006922657684247295,0.006807661542650826,0.006776817476379236,0.006739954496641897,0.007113984430155416,0.006991951687645109,0.006872894393668381,0.006796174387081926,0.006945833893698688,0.00675556606684136,0.006818194598367341,0.00700595791853156,0.006978332069540226,0.006870914441691238,0.006897047029786283,0.0068364100633495975,0.006983501177514661,0.006842527555135483,0.006877751065826681,0.006936953032642007,0.006931276589032823,0.0068704757574827285,0.006833578984376913,0.006867310417730998,0.006873004756558868,0.006884710099456298,0.006907031121995299,0.00683661280855649,0.006860597018944973,0.006859779556785654,0.006868781914119045,0.0068520872475575185,0.00685290907794107,0.006855455701494977,0.006863644872564473,0.006859414146477686,0.006859512262913219,0.006864737454797687,0.006851323462157685,0.0068320581059292,0.006836622120855949,0.006852198741954246,0.006860560164979421,0.006859139147799471,0.006857930826235428,0.006857614123784925,0.006856880665385163,0.006855455966829543,0.006857803510425385,0.006855062995080752,0.006854575264848877,0.006853524324418931,0.00685351609672429,0.006854534397954522,0.006854757836050616,0.006855871733479959,0.00685550293088608,0.006854636034000994,0.006853551396118679,0.006853883679251258,0.006853430103453704,0.006853588553179515,0.006852935355774854,0.006852922880452187,0.006851980529792822,0.006852315278206021,0.00685383935807121,0.006853382859777921,0.006854028849013859,0.006854357128345343,0.006853811756712468,0.00685513225102143,0.006857374067375504,0.00685637077936029],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Loss\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"RMSE\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Model Loss\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Model RMSE\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Training and Validation Loss and RMSE\"},\"height\":400,\"width\":1200,\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('d1d5823c-35c9-464a-b13a-0b24510ef0bf');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"code","source":"# –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ 'model' - —ç—Ç–æ –≤–∞—à–∞ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å\nmodel.save('/kaggle/working/SPX/1d/keras2/ETH1H_5Mpar11ENTRY4barsoutyfin100IN21epoch.keras')  # –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª—å –≤ –µ–¥–∏–Ω—ã–π —Ñ–∞–π–ª HDF5","metadata":{"execution":{"iopub.status.busy":"2024-06-02T19:12:46.847664Z","iopub.execute_input":"2024-06-02T19:12:46.848350Z","iopub.status.idle":"2024-06-02T19:12:47.093326Z","shell.execute_reply.started":"2024-06-02T19:12:46.848316Z","shell.execute_reply":"2024-06-02T19:12:47.092514Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# –§—É–Ω–∫—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö\ndef save_model_metadata(model, optimizer, history, ticker, timeframe, train_size, val_size, output_dir):\n    timestamp = time.strftime('%Y-%m-%d_%H-%M-%S')\n    metadata_filename = f'{output_dir}/model_metadata_{timestamp}.json'\n    model_config = model.to_json()\n    optimizer_config = optimizer.get_config()\n    metadata = {\n        'model_structure': model_config,\n        'optimizer_config': optimizer_config,\n        'train_loss': history.history['loss'],\n        'val_loss': history.history['val_loss'],\n        'train_rmse': history.history['rmse'],\n        'val_rmse': history.history['val_rmse'],\n        'ticker': ticker,\n        'timeframe': timeframe,\n        'train_size': train_size,\n        'val_size': val_size\n    }\n    with open(metadata_filename, 'w') as f:\n        json.dump(metadata, f, indent=4)\n    print(f'Model metadata saved to {metadata_filename}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Wrangle","metadata":{"id":"tBPeklrtlPmW"}},{"cell_type":"code","source":"import pandas as pd\n\n# –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É\nfile_path = '/kaggle/working/data/huobi-GALAUSDT-15.pkl'\n\n# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞\ndata = pd.read_pickle(file_path)\ndata.dropna(inplace=True)\n# –í—ã–≤–æ–¥ –≤—Å–µ—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–∞—Ç–∞—Å–µ—Ç–∞\nprint(data.columns.tolist())\ndata.columns = ['open', 'high', 'low', 'Close', 'volume', 'date_close']\nprint(data.columns.tolist())\ndata","metadata":{"executionInfo":{"elapsed":512,"status":"ok","timestamp":1711366846697,"user":{"displayName":"Ab As","userId":"09234410323733171058"},"user_tz":-300},"id":"uHz0Fsx8HYhi","outputId":"be86e630-5d3f-4b48-e6f0-fb79f0d0c1f7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É\nfile_path = '/kaggle/input/gala15/gala15min_agregate.csv'\n\n# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞\ndata = pd.read_csv(file_path)\n\n# –í—ã–≤–æ–¥ –≤—Å–µ—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–∞—Ç–∞—Å–µ—Ç–∞\nprint(data.columns.tolist())\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ 'date_open' –∫ —Ç–∏–ø—É datetime, –µ—Å–ª–∏ –æ–Ω —É–∂–µ –Ω–µ –≤ —ç—Ç–æ–º —Ñ–æ—Ä–º–∞—Ç–µ\ndata['date_open'] = pd.to_datetime(data['date_open'])\n\n# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å—Ç–æ–ª–±—Ü–∞ 'date_open' –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∏–Ω–¥–µ–∫—Å–∞ DataFrame\ndata.set_index('date_open', inplace=True)\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import yfinance as yf\n\n# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\ndata = yf.download('BTC-USD', period=\"max\")\n\n# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Å—Ç–æ–ª–±—Ü–∞ 'Date'\nprint(data.head())  # –°–Ω–∞—á–∞–ª–∞ –ø–µ—á–∞—Ç–∞–µ–º, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö\n\n# –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ 'Adj Close'\ndata.drop('Adj Close', axis=1, inplace=True)\n\n# –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è —Å—Ç–æ–ª–±—Ü–æ–≤\ndata.columns = ['open', 'high', 'low', 'Close', 'volume']\n\n# –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å –ø—É—Å—Ç—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏\ndata.dropna(inplace=True)\n\n# –ü–µ—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\nprint(data.head())\ndata\n","metadata":{"id":"ZLB9JI9FmJqy","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import yfinance as yf\n\ndata = yf.download('AAPL', start='1990-01-01', interval='1d')\ndata.reset_index(inplace=True)\ndata\n","metadata":{"id":"pVF_Y_a8inik","executionInfo":{"status":"ok","timestamp":1710966616010,"user_tz":-300,"elapsed":6146,"user":{"displayName":"Ab As","userId":"09234410323733171058"}},"outputId":"19ece65b-3901-4f15-c4e4-4634743aee80","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import yfinance as yf\n\n# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–æ—Å—Ç—É–ø–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞\ndata = yf.download('SPX')\ndata.reset_index(inplace=True)\ndata\n","metadata":{"id":"kzoGmEt5BkTC","executionInfo":{"status":"ok","timestamp":1711484955125,"user_tz":-300,"elapsed":1120,"user":{"displayName":"Ab As","userId":"09234410323733171058"}},"outputId":"68efc80a-d7f4-443c-c261-fa9993b2fa95","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ma_100_days = data.Close.rolling(100).mean()\nplt.figure(figsize=(8,6))\nplt.plot(ma_100_days, 'r')\nplt.plot(data.Close, 'g')\nplt.show()","metadata":{"executionInfo":{"elapsed":810,"status":"ok","timestamp":1711109319381,"user":{"displayName":"Ab As","userId":"09234410323733171058"},"user_tz":-300},"id":"9dfdbNQS62Ca","outputId":"bbdb3f92-940b-44a6-f085-958dddbb5619"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ma_200_days = data.Close.rolling(200).mean()\n\nplt.figure(figsize=(16,8))\nplt.plot(ma_100_days, 'r')\nplt.plot(ma_200_days, 'b')\nplt.plot(data.Close, 'g')\nplt.show()\n","metadata":{"executionInfo":{"elapsed":594,"status":"ok","timestamp":1711109323491,"user":{"displayName":"Ab As","userId":"09234410323733171058"},"user_tz":-300},"id":"YZjzw0gR-8wr","outputId":"0e0a8649-3127-40ce-8916-16ac661fa1ce"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# –°–Ω–∞—á–∞–ª–∞ —É–±–µ–¥–∏–º—Å—è, —á—Ç–æ –Ω–µ—Ç –Ω—É–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ —Å—Ç–æ–ª–±—Ü–µ volume, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å\ndata = data[data['volume'] != 0]\n\n# –¢–µ–ø–µ—Ä—å —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ä–∞–∑–Ω–∏—Ü—É –æ–±—ä–µ–º–∞ –∫–∞–∫ –ø—Ä–æ—Ü–µ–Ω—Ç –æ—Ç –æ–±—â–µ–≥–æ –æ–±—ä–µ–º–∞\ndata['voldiff_pct'] = (data['voldiff'] / data['volume']) * 100\n\n# –¢–µ–ø–µ—Ä—å –≤—ã–±–∏—Ä–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, –≤–∫–ª—é—á–∞—è –Ω–æ–≤—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–π —Å—Ç–æ–ª–±–µ—Ü\nfeatures = ['open', 'high', 'low', 'Close', 'volume', 'voldiff']\n\n# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–æ—á–∫—É —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏ (80% –æ—Ç –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö)\nsplit_index = int(len(data) * 0.80)\n\n# –°–æ–∑–¥–∞–µ–º –æ–±—É—á–∞—é—â—É—é –≤—ã–±–æ—Ä–∫—É —Å –Ω–æ–≤—ã–º –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–º —Å—Ç–æ–ª–±—Ü–æ–º\ndata_train = data[features].iloc[:split_index]\n\n# –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫—É\ndata_test = data[features].iloc[split_index:]\n\n# –ü–µ—á–∞—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\nprint(data_train.head())\n\n# –ü–µ—á–∞—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\nprint(data_test.head())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **–ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –±–µ–∑ voldiff **","metadata":{}},{"cell_type":"code","source":"# –°–Ω–∞—á–∞–ª–∞ —É–±–µ–¥–∏–º—Å—è, —á—Ç–æ –Ω–µ—Ç –Ω—É–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ —Å—Ç–æ–ª–±—Ü–µ volume, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å\ndata = data[data['volume'] != 0]\n\n# –¢–µ–ø–µ—Ä—å –≤—ã–±–∏—Ä–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, –ù–ï –≤–∫–ª—é—á–∞—è –Ω–æ–≤—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–π —Å—Ç–æ–ª–±–µ—Ü –∏ 'voldiff'\nfeatures = ['open', 'high', 'low', 'Close', 'volume']\n\n# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–æ—á–∫—É —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏ (80% –æ—Ç –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö)\nsplit_index = int(len(data) * 0.80)\n\n# –°–æ–∑–¥–∞–µ–º –æ–±—É—á–∞—é—â—É—é –≤—ã–±–æ—Ä–∫—É –±–µ–∑ 'voldiff' –∏ 'voldiff_pct'\ndata_train = data[features].iloc[:split_index]\n\n# –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫—É\ndata_test = data[features].iloc[split_index:]\n\n# –ü–µ—á–∞—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\nprint(data_train.head())\n\n# –ü–µ—á–∞—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\nprint(data_test.head())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.dropna(inplace=True)\n\ndata_train = pd.DataFrame(data.Close[0: int(len(data)*0.80)])\ndata_test = pd.DataFrame(data.Close[int(len(data)*0.80): len(data)])","metadata":{"executionInfo":{"elapsed":432,"status":"ok","timestamp":1711485493765,"user":{"displayName":"Ab As","userId":"09234410323733171058"},"user_tz":-300},"id":"N-5OAeiQ_bSt","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train.shape","metadata":{"executionInfo":{"elapsed":267,"status":"ok","timestamp":1711485496326,"user":{"displayName":"Ab As","userId":"09234410323733171058"},"user_tz":-300},"id":"i-D2LW_DKaax","outputId":"591ed417-6c74-4a32-a672-057a458049be","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train","metadata":{"id":"aPJs4LmTY41e","executionInfo":{"status":"ok","timestamp":1711482284636,"user_tz":-300,"elapsed":9,"user":{"displayName":"Ab As","userId":"09234410323733171058"}},"outputId":"42e12ed6-1dea-45a3-87a5-9d5c4f9b189a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_test.shape","metadata":{"executionInfo":{"elapsed":408,"status":"ok","timestamp":1711485499797,"user":{"displayName":"Ab As","userId":"09234410323733171058"},"user_tz":-300},"id":"y2rzL3QpKhGu","outputId":"cd99c84c-1e45-4c9f-ee37-a2c66a7ed9b1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))\n\ndata_train_scale = scaler.fit_transform(data_train)\n\nimport joblib\n!mkdir -p /kaggle/working/GALA/15m/keras/\n\n# –ü—É—Ç—å, –∫—É–¥–∞ –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω scaler\nscaler_filename = '/kaggle/working/GALA/15m/keras/scaler.save'\n\n# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ scaler\njoblib.dump(scaler, scaler_filename)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))","metadata":{"executionInfo":{"elapsed":400,"status":"ok","timestamp":1711485502762,"user":{"displayName":"Ab As","userId":"09234410323733171058"},"user_tz":-300},"id":"UuPzIO9xBTGE","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train_scale = scaler.fit_transform(data_train)","metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1711485503627,"user":{"displayName":"Ab As","userId":"09234410323733171058"},"user_tz":-300},"id":"5SJ1k1MQAwQv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import joblib\n!mkdir -p /kaggle/working/ETH/1H/keras/\n\n# –ü—É—Ç—å, –∫—É–¥–∞ –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω scaler\nscaler_filename = '/kaggle/working/ETH/1H/keras/scaler.save'\n\n# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ scaler\njoblib.dump(scaler, scaler_filename)","metadata":{"id":"azRsyqqfiNmA","executionInfo":{"status":"ok","timestamp":1711485505367,"user_tz":-300,"elapsed":5,"user":{"displayName":"Ab As","userId":"09234410323733171058"}},"outputId":"73c864eb-8793-42d3-e86f-4f80b43bf22d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import joblib\nscaler_original = scaler\n# –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ scaler_original - —ç—Ç–æ –≤–∞—à –∏—Å—Ö–æ–¥–Ω—ã–π —Å–∫–∞–ª–µ—Ä.\n# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ —Å–∫–∞–ª–µ—Ä–∞ –∏–∑ —Ñ–∞–π–ª–∞.\nscaler_loaded = joblib.load('/content/drive/MyDrive/gala/keras/scaler.save')\n\n# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞—Ç—Ä–∏–±—É—Ç–æ–≤ —Å–∫–∞–ª–µ—Ä–æ–≤.\nattributes_to_compare = ['min_', 'scale_', 'data_min_', 'data_max_', 'data_range_']\n\nfor attr in attributes_to_compare:\n    original_attr_value = getattr(scaler_original, attr, 'Attribute not found')\n    loaded_attr_value = getattr(scaler_loaded, attr, 'Attribute not found')\n    if np.array_equal(original_attr_value, loaded_attr_value):\n        print(f\"{attr} is identical between scalers.\")\n    else:\n        print(f\"{attr} is different between scalers.\")\n        print(f\"Original: {original_attr_value}\")\n        print(f\"Loaded: {loaded_attr_value}\")\n","metadata":{"id":"iAtXo8A3vpPK","executionInfo":{"status":"ok","timestamp":1711366931181,"user_tz":-300,"elapsed":806,"user":{"displayName":"Ab As","userId":"09234410323733171058"}},"outputId":"4e14847d-fb24-4cd2-db3e-93777d80b6c7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö X –∏ Y\nx = []\ny = []\n\nfor i in range(100, data_train_scale.shape[0]):\n    x.append(data_train_scale[i-100:i])\n    # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ —Ü–µ–ª—å—é —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è 'Close', –∫–æ—Ç–æ—Ä–æ–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —á–µ—Ç–≤–µ—Ä—Ç–æ–º —Å—Ç–æ–ª–±—Ü–µ –ø–æ—Å–ª–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è\n    y.append(data_train_scale[i, 3])\n\nx, y = np.array(x), np.array(y)\n\n# –ò–∑–º–µ–Ω—è–µ–º —Ñ–æ—Ä–º—É x –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–æ–≤–æ–≥–æ –∏–∑–º–µ—Ä–µ–Ω–∏—è, —Ç–∞–∫ –∫–∞–∫ LSTM –æ–∂–∏–¥–∞–µ—Ç —Ç—Ä–µ—Ö–º–µ—Ä–Ω—ã–π —Ç–µ–Ω–∑–æ—Ä –≤ —Ñ–æ—Ä–º–∞—Ç–µ [samples, timesteps, features]\n# –í –≤–∞—à–µ–º —Å–ª—É—á–∞–µ 'features' —Ä–∞–≤–Ω–æ 5, —Ç–∞–∫ –∫–∞–∫ —É –≤–∞—Å 5 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\nx = np.reshape(x, (x.shape[0], x.shape[1], 5))","metadata":{"executionInfo":{"elapsed":256,"status":"ok","timestamp":1711485510436,"user":{"displayName":"Ab As","userId":"09234410323733171058"},"user_tz":-300},"id":"KJlUa6rjAzkj","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Dense, Dropout, LSTM\nfrom keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(LSTM(units=50, activation='relu', return_sequences=True, input_shape=(x.shape[1], 1)))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units=60, activation='relu', return_sequences=True))\nmodel.add(Dropout(0.3))\n\nmodel.add(LSTM(units=80, activation='relu', return_sequences=True))\nmodel.add(Dropout(0.4))\n\nmodel.add(LSTM(units=120, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(units=1))","metadata":{"executionInfo":{"elapsed":1568,"status":"ok","timestamp":1711485017706,"user":{"displayName":"Ab As","userId":"09234410323733171058"},"user_tz":-300},"id":"ZDMigo1VCInW","outputId":"72f58be8-dbca-447d-84ec-887502c42a01","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# –ú–æ–¥–µ–ª—å –ø–æ–¥ 5 –≤—Ö–æ–¥–æ–≤","metadata":{}},{"cell_type":"code","source":"from keras.layers import Dense, Dropout, LSTM\nfrom keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(LSTM(units=50, activation='relu', return_sequences=True, input_shape=(x.shape[1], x.shape[2])))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units=60, activation='relu', return_sequences=True))\nmodel.add(Dropout(0.3))\n\nmodel.add(LSTM(units=80, activation='relu', return_sequences=True))\nmodel.add(Dropout(0.4))\n\nmodel.add(LSTM(units=120, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(units=1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# –ú–æ–¥–µ–ª—å 5 –≤—Ö–æ–¥–æ–≤ —Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –Ω–∞ 2  GPU ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom tensorflow.keras.models import Sequential\n\n# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n# –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ x –∏ y —É–∂–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º\n# –ù–∞–ø—Ä–∏–º–µ—Ä:\n# x, y = get_data() # —Ñ—É–Ω–∫—Ü–∏—è get_data –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n\n# –°–æ–∑–¥–∞–π—Ç–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º GPU\nstrategy = tf.distribute.MirroredStrategy(devices=[\"GPU:0\", \"GPU:1\"])\n\nwith strategy.scope():\n    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤–Ω—É—Ç—Ä–∏ scope\n    model = Sequential()\n    model.add(LSTM(units=50, activation='relu', return_sequences=True, input_shape=(x.shape[1], x.shape[2])))\n    model.add(Dropout(0.2))\n\n    model.add(LSTM(units=60, activation='relu', return_sequences=True))\n    model.add(Dropout(0.3))\n\n    model.add(LSTM(units=80, activation='relu', return_sequences=True))\n    model.add(Dropout(0.4))\n\n    model.add(LSTM(units=120, activation='relu'))\n    model.add(Dropout(0.5))\n\n    model.add(Dense(units=1))\n\n    # –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏ —Ç–∞–∫–∂–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤–Ω—É—Ç—Ä–∏ scope\n    model.compile(optimizer='adam', loss='mean_squared_error')\n\n# –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª—å\nmodel.fit(x, y, epochs=50, batch_size=32, verbose=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"–ú–æ–¥–µ–ª—å —Å–æ —à—Ç–∞—Ä—Ñ–∞–º–∏ —Å–ª–æ–µ–≤ + 2 —Å–ª–æ—è –∏ –±–æ–ª—å—à–µ –Ω–µ–π—Ä–æ–Ω–æ–≤ –Ω–∞ —Å–ª–æ–π –≤ –¥–≤–∞ —Ä–∞–∑–∞","metadata":{"id":"-BqrKmbdR5ux"}},{"cell_type":"code","source":"from keras.layers import Bidirectional, LSTM, Dense, Dropout\nfrom keras.models import Sequential\nfrom keras.regularizers import l2–Ω—Ä\n\nmodel = Sequential()\n\nmodel.add(LSTM(units=60, activation='relu', return_sequences=True, kernel_regularizer=l2(0.01)))\nmodel.add(Dropout(0.3))\n\nmodel.add(LSTM(units=80, activation='relu', return_sequences=True, kernel_regularizer=l2(0.01)))\nmodel.add(Dropout(0.4))\n\n# –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —Å–ª–æ–∏ LSTM —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –Ω–µ–π—Ä–æ–Ω–æ–≤\nmodel.add(LSTM(units=120, activation='relu', return_sequences=True, kernel_regularizer=l2(0.01)))\nmodel.add(Dropout(0.4))\n\nmodel.add(LSTM(units=240, activation='relu', return_sequences=False, kernel_regularizer=l2(0.01))) # –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ: –ø–æ—Å–ª–µ–¥–Ω–∏–π LSTM —Å–ª–æ–π –¥–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤—ã–≤–æ–¥\nmodel.add(Dropout(0.5))\n\n# –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π\nmodel.add(Dense(units=1, kernel_regularizer=l2(0.01)))\n\n","metadata":{"id":"EIGIyUXLR5HO","executionInfo":{"status":"ok","timestamp":1711486565533,"user_tz":-300,"elapsed":277,"user":{"displayName":"Ab As","userId":"09234410323733171058"}},"outputId":"4984cd79-10b8-4b4a-8c98-60ea0c1d6c97"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='mean_squared_error')","metadata":{"id":"gmDUFdPHDRYp","executionInfo":{"status":"ok","timestamp":1711486569088,"user_tz":-300,"elapsed":299,"user":{"displayName":"Ab As","userId":"09234410323733171058"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(x, y, epochs=50, batch_size=32, verbose=1)","metadata":{"id":"xc3Nf_QhCwNs","executionInfo":{"status":"ok","timestamp":1711487684438,"user_tz":-300,"elapsed":1107259,"user":{"displayName":"Ab As","userId":"09234410323733171058"}},"outputId":"c8972cb1-e48d-47a9-f9cd-74a858a1a873","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# –¢–µ—Å—Ç –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞","metadata":{}},{"cell_type":"code","source":"# –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ 'model' - —ç—Ç–æ –≤–∞—à–∞ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å\nmodel.save('/kaggle/working/ETH/1H/keras/ETH1hOHLCVhuobi100IN.keras')  # –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª—å –≤ –µ–¥–∏–Ω—ã–π —Ñ–∞–π–ª HDF5\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport joblib\nfrom keras.models import load_model\nfrom sklearn.preprocessing import MinMaxScaler\n# –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ data —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã, –∞ data_train –∏ data_test –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã\n\n# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏\nmodel = load_model('/kaggle/input/galamd/GALA/keras/gala15FULLepoch100.keras')\n\n# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ scaler\nscaler = joblib.load('/kaggle/input/galamd/GALA/keras/scaler.save')\n\n# –î–æ–ø–æ–ª–Ω–µ–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ 100 –¥–Ω—è–º–∏ –∏–∑ –æ–±—É—á–∞—é—â–µ–≥–æ –Ω–∞–±–æ—Ä–∞\npas_100_days = data_train.tail(100)\ndata_test = pd.concat([pas_100_days, data_test], ignore_index=True)\n\n# –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è 'Close' –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\ny_original = data_test['Close'].values  # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç—É —á–∞—Å—Ç—å, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º, –±–µ–∑ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–Ω–µ–π\ny_original = y_original[100:]\n\n# –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\ndata_test_scaled = scaler.fit_transform(data_test)\n\n# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏\nx_test = []\nfor i in range(100, len(data_test_scaled)):\n    x_test.append(data_test_scaled[i-100:i])\nx_test = np.array(x_test)\n\n# –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ x_test –∫ —Ç—Ä–µ–±—É–µ–º–æ–π —Ñ–æ—Ä–º–µ –¥–ª—è –º–æ–¥–µ–ª–∏\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], len(features)))\n\n# –ò–Ω—Ñ–µ—Ä–µ–Ω—Å\ny_predict = model.predict(x_test)\n\n# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è\ntemp_array = np.zeros((len(y_predict), len(features)))  # –°–æ–∑–¥–∞–µ–º –º–∞—Å—Å–∏–≤ –∏–∑ –Ω—É–ª–µ–π\ntemp_array[:, features.index('Close')] = y_predict.reshape(-1)  # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏\ny_predict_original = scaler.inverse_transform(temp_array)[:, features.index('Close')]  # –û–±—Ä–∞—Ç–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport joblib\nfrom keras.models import load_model\nfrom sklearn.preprocessing import MinMaxScaler\n# –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ data —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã, –∞ data_train –∏ data_test –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã\n# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏\nmodel = load_model('/kaggle/input/galamd/GALA/keras/gala15FULLepoch100.keras')\n\n# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ scaler\nscaler = joblib.load('/kaggle/input/galamd/GALA/keras/scaler.save')\n\n# –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è 'Close' –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\ny_original = data_test['Close'].values\n\n# –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\ndata_test_scaled = scaler.fit_transform(data_test)\n\n# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏\nx_test = []\nfor i in range(len(data_test_scaled) - 99):\n    x_test.append(data_test_scaled[i:i+100])\nx_test = np.array(x_test)\n\n\n# –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ x_test –∫ —Ç—Ä–µ–±—É–µ–º–æ–π —Ñ–æ—Ä–º–µ –¥–ª—è –º–æ–¥–µ–ª–∏\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], len(features)))\n\n# –ò–Ω—Ñ–µ—Ä–µ–Ω—Å\ny_predict = model.predict(x_test)\n\n# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è\ntemp_array = np.zeros((len(y_predict), len(features)))  # –°–æ–∑–¥–∞–µ–º –º–∞—Å—Å–∏–≤ –∏–∑ –Ω—É–ª–µ–π\ntemp_array[:, features.index('Close')] = y_predict.reshape(-1)  # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏\ny_predict_original = scaler.inverse_transform(temp_array)[:, features.index('Close')]  # –û–±—Ä–∞—Ç–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**–ì—Ä–∞—Ñ–∏–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –Ω–∞ —Ç—Ä–µ–π–Ω –∏ —Ç–µ—Å—Ç –¥–∞—Ç–∞**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nplt.plot(y_predict_original, 'r', label='Predicted Price')\nplt.plot(y_original, 'g', label='Original Price')\nplt.xlabel('Time')\nplt.ylabel('Price')\nplt.legend()\nplt.show()\n","metadata":{"executionInfo":{"elapsed":995,"status":"ok","timestamp":1711367032451,"user":{"displayName":"Ab As","userId":"09234410323733171058"},"user_tz":-300},"id":"aDiZBYeDIQYb","outputId":"e44db76f-3404-4c6b-fe29-768d88ba82b1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\n# RMSE –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤\nrmse = np.sqrt(mean_squared_error(y_original, y_predict_original))\n\n# –ü–µ—á–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è RMSE\nprint(f\"RMSE: {rmse}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predict_original.shape\ny_predict_original","metadata":{"id":"xguwiwWKeZkP","executionInfo":{"status":"ok","timestamp":1711487801723,"user_tz":-300,"elapsed":284,"user":{"displayName":"Ab As","userId":"09234410323733171058"}},"outputId":"19379a16-1aeb-4477-c548-4c097c9ec83a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_original.shape\ny_original","metadata":{"id":"GO97HRnRefrc","executionInfo":{"status":"ok","timestamp":1711485366266,"user_tz":-300,"elapsed":656,"user":{"displayName":"Ab As","userId":"09234410323733171058"}},"outputId":"f0bce704-8087-47a8-828b-0bf83f833737","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_original.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predict_original.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# –í—ã–±–æ—Ä –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 20 –∑–Ω–∞—á–µ–Ω–∏–π –∏–∑ –∫–∞–∂–¥–æ–≥–æ –º–∞—Å—Å–∏–≤–∞\ny_predict_last_20 = y_predict_original[-500:]*1.087\ny_original_last_20 = y_original[-500:]\n\nplt.figure(figsize=(10,8))\nplt.plot(y_predict_last_20, 'r', label='Predicted Price Shifted')\nplt.plot(y_original_last_20, 'g', label='Original Price')\nplt.xlabel('Time')\nplt.ylabel('Price')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\n\ny_predict_last_20 = y_predict_original[-100:]*1.087\ny_original_last_20 = y_original[-100:]\n\n\n# –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç Figure –¥–ª—è Plotly\nfig = go.Figure()\n\n# –î–æ–±–∞–≤–ª—è–µ–º –ª–∏–Ω–∏–∏ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫\nfig.add_trace(go.Scatter(x=list(range(len(y_predict_last_20))), y=y_predict_last_20,\n                         mode='lines', name='Predicted Price Shifted'))\nfig.add_trace(go.Scatter(x=list(range(len(y_original_last_20))), y=y_original_last_20,\n                         mode='lines', name='Original Price'))\n\n# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ–¥–ø–∏—Å–∏ –æ—Å–µ–π –∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫\nfig.update_layout(title='Price Comparison',\n                  xaxis_title='Time',\n                  yaxis_title='Price')\n\n# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≥—Ä–∞—Ñ–∏–∫\nfig.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}